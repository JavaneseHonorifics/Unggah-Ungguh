{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa51cee",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Conversation Generation with Persona</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de97983",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94bde86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch evaluate transformers accelerate>=0.26.0 sentencepiece einops sacrebleu google.generativeai openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5468cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer, \n",
    "    GenerationConfig, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from huggingface_hub import login\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72129821",
   "metadata": {},
   "source": [
    "## Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4dccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "OPEN_API_KEY = os.getenv(\"OPEN_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "MODELS = [\n",
    "    \"GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct\",\n",
    "    \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"sail/Sailor2-8B\",\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    \"google/gemma-2-9b-it\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8516c5",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e86ec7b-fdb4-4737-b697-53d33f399946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fccd53d31a4fbcabba0e5c577dd569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.csv:   0%|          | 0.00/57.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3e13f56e56477395327a0a01230d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"JavaneseHonorifics/Unggah-Ungguh\", \"conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b57e5e-c822-4fe4-8e35-f1e707aa2c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 1,\n",
       " 'role a': 'Peer',\n",
       " 'role b': 'Peer',\n",
       " 'context': \"Speaker A asks speaker B about what Speaker B's father ate today. Speaker A and Speaker B have equal status or position and have familiar interactions.\",\n",
       " 'a utterance': 'Bapakmu dhahar apa dina iki?',\n",
       " 'a utterance category': 1,\n",
       " 'b utterance': 'Bapakku dhahar pecel dina iki.',\n",
       " 'b utterance category': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6c15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_category_to_number(category):\n",
    "    category_mapping = {\n",
    "        'Ngoko': 0,\n",
    "        'Ngoko lugu': 0,\n",
    "        'Ngoko alus': 1,\n",
    "        'Krama': 2,\n",
    "        'Krama madya': 2,\n",
    "        'Krama alus': 3\n",
    "    }\n",
    "    return category_mapping.get(category.strip(), -1)\n",
    "\n",
    "def excel_to_dataset_dict(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    df['A Utterance Category'] = df['A Utterance Category'].apply(map_category_to_number)\n",
    "    df['B Utterance Category'] = df['B Utterance Category'].apply(map_category_to_number)\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        'Role A': 'role_a',\n",
    "        'Role B': 'role_b',\n",
    "        'Context': 'context',\n",
    "        'A Utterance': 'a_utterance',\n",
    "        'A Utterance Category': 'a_utterance_category',\n",
    "        'B Utterance': 'b_utterance',\n",
    "        'B Utterance Category': 'b_utterance_category'\n",
    "    })\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    \n",
    "    dataset_dict = DatasetDict({\n",
    "        'train': dataset\n",
    "    })\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaca15f",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e627345",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "797d1f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a6207916e74d85bdf64b8db55d8196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/scratch/2497254.1.ivcbuyin/ipykernel_1559547/4122142561.py\", line 5, in <module>\n",
      "    model1 = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 4256, in from_pretrained\n",
      "    model.generation_config = GenerationConfig.from_pretrained(\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 1102, in from_pretrained\n",
      "    config = cls.from_dict(config_dict, **kwargs)\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 1137, in from_dict\n",
      "    config = cls(**{**config_dict, **kwargs})\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 509, in __init__\n",
      "    self.validate(is_init=True)\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 789, in validate\n",
      "    logger.warning_once(\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/utils/logging.py\", line 328, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.'\n",
      "Arguments: (<class 'UserWarning'>,)\n"
     ]
    }
   ],
   "source": [
    "model_name_1 = MODELS[0] # \"GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct\"\n",
    "\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model_name_1)\n",
    "\n",
    "model1 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_1,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fb16c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cfffa5ca474933be13cc5e50ebbcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_2 = MODELS[1] # \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\"\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_name_2)\n",
    "\n",
    "model2 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_2,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2b34259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bcb73095804857bbbf8a876e4fe887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_3 = MODELS[2] # \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(model_name_3)\n",
    "\n",
    "model3 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_3,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d10611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3115e4562b427aa7e0795e8ccb23fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_4 = MODELS[3] # \"sail/Sailor2-8B\"\n",
    "\n",
    "tokenizer4 = AutoTokenizer.from_pretrained(model_name_4)\n",
    "\n",
    "model4 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_4,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75701755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb77cbf42014ef3b67784ef029cd3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_5 = MODELS[4] # \"google/gemma-2-2b-it\"\n",
    "\n",
    "tokenizer5 = AutoTokenizer.from_pretrained(model_name_5)\n",
    "\n",
    "model5 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_5,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9bbdfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cb86754a4445ae8ce6c992cfeef486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_6 = MODELS[5] # \"google/gemma-2-9b-it\"\n",
    "\n",
    "tokenizer6 = AutoTokenizer.from_pretrained(model_name_6)\n",
    "\n",
    "model6 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_6,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b851bda",
   "metadata": {},
   "source": [
    "## Define Variabel to Store Inference Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90d1f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"model1\", \"model2\", \"model3\", \"model4\", \"model5\", \"model6\",\n",
    "    \"modelOpenAI\", \"modelGemini\"\n",
    "]\n",
    "\n",
    "for hint in [\"noHint\", \"withHint\"]:\n",
    "    for speaker in [\"A\", \"B\"]:\n",
    "        for model in model_names:\n",
    "            globals()[f\"{model}_{hint}_{speaker}\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b11036f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, data, hint=False):\n",
    "    generation_config = GenerationConfig(\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        do_sample=True,\n",
    "        early_stopping=True,\n",
    "        repetition_penalty=1.2,\n",
    "        min_length=10,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    "    A = []\n",
    "    B = []\n",
    "    \n",
    "    data = data['train']\n",
    "    \n",
    "    for idx, item in enumerate(data):\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        prompt = f\"\"\"Create a conversation between A as {item[\"role a\"]} and B as {item[\"role b\"]} in Javanese language with this context: `{item[\"context\"]}`\\n\"\"\"\n",
    "        prompt += \"Please follow this format:\\n\"\n",
    "        prompt += \"A: `<UTTERANCE>`\\n\"\n",
    "        prompt += \"B: `<UTTERANCE>`\\n\\n\"\n",
    "        if hint:\n",
    "            prompt += \"Use this Javanese's honorific level usage as a hint:\\n\"\n",
    "            prompt += \"1. Ngoko Ngoko:\\n\"\n",
    "            prompt += \"- Used for informal conversations with peers or lower-status individuals\\n\"\n",
    "            prompt += \"- Common in close relationships or familiar interactions\\n\"\n",
    "            prompt += \"2. Ngoko Alus:\\n\"\n",
    "            prompt += \"- Adds respect when speaking to equals or higher-status individuals in informal or close relationships\\n\"\n",
    "            prompt += \"- Flexible for conversations with mixed-status participants\\n\"\n",
    "            prompt += \"- Talked with a person with equals status about other person who has a higher-status\\n\"\n",
    "            prompt += \"3. Krama:\\n\"\n",
    "            prompt += \"- Used for respectful conversations with equals or lower-status individuals, especially when not close\\n\"\n",
    "            prompt += \"- Suitable for maintaining formality in less familiar interactions\\n\"\n",
    "            prompt += \"4. Krama Alus:\\n\"\n",
    "            prompt += \"- Expresses high respect in conversations with higher-status individuals or unfamiliar equals\\n\"\n",
    "            prompt += \"- Essential for formal interactions requiring utmost politeness\\n\"\n",
    "            prompt += \"- Talked with a person with higher-status about other person who has a higher-status\\n\"\n",
    "        prompt += \"Answer:\\n\"\n",
    "        \n",
    "        model_input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "        \n",
    "        try:\n",
    "            outputs = model.generate(\n",
    "                input_ids=model_input_ids,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "            decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            del outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            decoded_output = decoded_output.replace(\"```java\", \"\").replace(\"```javanese\", \"\").replace(\"```jawa\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "            a_count = 0\n",
    "            b_count = 0\n",
    "            a_utterance = \"\"\n",
    "            b_utterance = \"\"\n",
    "\n",
    "            lines = decoded_output.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"A:\"):\n",
    "                    a_count += 1\n",
    "                    if a_count == 2:\n",
    "                        if '\"' in line:\n",
    "                            a_utterance = line[line.find('\"'):line.rfind('\"')+1].strip('\"')\n",
    "                        else:\n",
    "                            a_utterance = line.replace(\"A:\", \"\").strip()\n",
    "                elif line.startswith(\"B:\"):\n",
    "                    b_count += 1\n",
    "                    if b_count == 2:\n",
    "                        if '\"' in line:\n",
    "                            b_utterance = line[line.find('\"'):line.rfind('\"')+1].strip('\"')\n",
    "                        else:\n",
    "                            b_utterance = line.replace(\"B:\", \"\").strip()\n",
    "\n",
    "            a_utterance = a_utterance.strip('`').strip()\n",
    "            b_utterance = b_utterance.strip('`').strip()\n",
    "\n",
    "            print(f\"\\nInstance {idx + 1}:\")\n",
    "            print(f\"Role A: {item['role_a']}\")\n",
    "            print(f\"Role B: {item['role_b']}\")\n",
    "            print(f\"Context: {item['context']}\")\n",
    "            print(f\"Utterance A: {a_utterance}\")\n",
    "            print(f\"Utterance B: {b_utterance}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            A.append(a_utterance if a_utterance else \"\")\n",
    "            B.append(b_utterance if b_utterance else \"\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing instance {idx + 1}:\")\n",
    "            print(f\"Role A: {item['role_a']}\")\n",
    "            print(f\"Role B: {item['role_b']}\")\n",
    "            print(f\"Context: {item['context']}\")\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            print(\"-\" * 50)\n",
    "            A.append(\"\")\n",
    "            B.append(\"\")\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"\\nDONE\")\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26cdf8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_api_model(data, model_type=\"openai\", hint=False):\n",
    "    A = []\n",
    "    B = []\n",
    "    \n",
    "    data = data[\"train\"]\n",
    "\n",
    "    rate_limiter = RateLimiter(min_delay_ms=1000)\n",
    "\n",
    "    if model_type == \"openai\":\n",
    "        client = OpenAI(api_key=OPEN_API_KEY)\n",
    "    elif model_type == \"gemini\":\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be either 'openai' or 'gemini'\")\n",
    "    \n",
    "    for idx, item in enumerate(data):\n",
    "        try:\n",
    "            prompt = f\"\"\"Create a conversation between A as {item[\"role_a\"]} and B as {item[\"role_b\"]} in Javanese language with this context: `{item[\"context\"]}`\\n\"\"\"\n",
    "            prompt += \"Please follow this format:\\n\"\n",
    "            prompt += \"A: `<UTTERANCE>`\\n\"\n",
    "            prompt += \"B: `<UTTERANCE>`\\n\\n\"\n",
    "            if hint:\n",
    "                prompt += \"Use this Javanese's honorific level usage as a hint:\\n\"\n",
    "                prompt += \"1. Ngoko Ngoko:\\n\"\n",
    "                prompt += \"- Used for informal conversations with peers or lower-status individuals\\n\"\n",
    "                prompt += \"- Common in close relationships or familiar interactions\\n\"\n",
    "                prompt += \"2. Ngoko Alus:\\n\"\n",
    "                prompt += \"- Adds respect when speaking to equals or higher-status individuals in informal or close relationships\\n\"\n",
    "                prompt += \"- Flexible for conversations with mixed-status participants\\n\"\n",
    "                prompt += \"- Talked with a person with equals status about other person who has a higher-status\\n\"\n",
    "                prompt += \"3. Krama:\\n\"\n",
    "                prompt += \"- Used for respectful conversations with equals or lower-status individuals, especially when not close\\n\"\n",
    "                prompt += \"- Suitable for maintaining formality in less familiar interactions\\n\"\n",
    "                prompt += \"4. Krama Alus:\\n\"\n",
    "                prompt += \"- Expresses high respect in conversations with higher-status individuals or unfamiliar equals\\n\"\n",
    "                prompt += \"- Essential for formal interactions requiring utmost politeness\\n\"\n",
    "                prompt += \"- Talked with a person with higher-status about other person who has a higher-status\\n\"\n",
    "            prompt += \"Answer:\\n\"\n",
    "\n",
    "            rate_limiter.wait()\n",
    "\n",
    "            if model_type == \"openai\":\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=100,\n",
    "                    top_p=0.9\n",
    "                )\n",
    "                decoded_output = response.choices[0].message.content\n",
    "                \n",
    "            else:\n",
    "                response = model.generate_content(\n",
    "                    prompt,\n",
    "                    generation_config=genai.types.GenerationConfig(\n",
    "                        temperature=0.7,\n",
    "                        top_p=0.9,\n",
    "                        top_k=50,\n",
    "                        max_output_tokens=100\n",
    "                    )\n",
    "                )\n",
    "                decoded_output = response.text\n",
    "\n",
    "            a_count = 0\n",
    "            b_count = 0\n",
    "            a_utterance = \"\"\n",
    "            b_utterance = \"\"\n",
    "\n",
    "            lines = decoded_output.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"A:\"):\n",
    "                    a_count += 1\n",
    "                    if a_count == 2:\n",
    "                        if '\"' in line:\n",
    "                            a_utterance = line[line.find('\"'):line.rfind('\"')+1].strip('\"')\n",
    "                        else:\n",
    "                            a_utterance = line.replace(\"A:\", \"\").strip()\n",
    "                elif line.startswith(\"B:\"):\n",
    "                    b_count += 1\n",
    "                    if b_count == 2:\n",
    "                        if '\"' in line:\n",
    "                            b_utterance = line[line.find('\"'):line.rfind('\"')+1].strip('\"')\n",
    "                        else:\n",
    "                            b_utterance = line.replace(\"B:\", \"\").strip()\n",
    "\n",
    "            a_utterance = a_utterance.strip('`').strip()\n",
    "            b_utterance = b_utterance.strip('`').strip()\n",
    "\n",
    "            print(f\"\\nInstance {idx + 1}:\")\n",
    "            print(f\"Role A: {item['role_a']}\")\n",
    "            print(f\"Role B: {item['role_b']}\")\n",
    "            print(f\"Context: {item['context']}\")\n",
    "            print(f\"Utterance A: {a_utterance}\")\n",
    "            print(f\"Utterance B: {b_utterance}\")\n",
    "            print(f\"Model: {model_type}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            A.append(a_utterance if a_utterance else \"\")\n",
    "            B.append(b_utterance if b_utterance else \"\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing instance {idx + 1}:\")\n",
    "            print(f\"Role A: {item['role_a']}\")\n",
    "            print(f\"Role B: {item['role_b']}\")\n",
    "            print(f\"Context: {item['context']}\")\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            print(f\"Model: {model_type}\")\n",
    "            print(\"-\" * 50)\n",
    "            A.append(\"\")\n",
    "            B.append(\"\")\n",
    "            continue\n",
    "            \n",
    "    print(\"\\nDONE\")\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc89e34c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 1:\n",
      "Role A: Teacher\n",
      "Role B: Student\n",
      "Context: Speaker A asked speaker B about what he had eaten today.  Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Lha lawuhe opo, Le? (And what was the side dish, son?)\n",
      "Utterance B: Tahu tempe kaliyan sambel thok, Bu. (Just tofu, tempeh, and sambal\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 2:\n",
      "Role A: Peer\n",
      "Role B: Peer\n",
      "Context: Speaker A asks speaker B about what Speaker B's father ate today. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 3:\n",
      "Role A: Older sibling\n",
      "Role B: Younger sibling\n",
      "Context: Speaker A asks speaker B about what Speaker B learned at school today. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: Sing basa Jawi mau sinau apa? Coba critakna! (What did you learn in Javanese class? Tell me!)\n",
      "Utterance B: Sinau\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 4:\n",
      "Role A: A friend from the same village who has not met each other for a long time\n",
      "Role B: A friend from the same village who has not met each other for a long time\n",
      "Context: Speaker A asks speaker B about the news from speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Alhamdulillah, apik. Kowe saiki kerjo neng endi? (Thank God, I'm fine. Where do you work now?)\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 5:\n",
      "Role A: The school canteen attendant.\n",
      "Role B: Students at school\n",
      "Context: Speaker A asks speaker B about the university he is going to. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Wah, apik kuwi. Jurusan apa sing arep kok pilih? (Wow, that's good\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 6:\n",
      "Role A: People who do not know each other\n",
      "Role B: People who do not know each other\n",
      "Context: Speaker A asked speaker B about the direction to Gadjah Mada University. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 7:\n",
      "Role A: Colleague (lecturer)\n",
      "Role B: Colleague (lecturer)\n",
      "Context: Speaker A asked speaker B about the number of students who entered the Javanese literature department. Speaker A and Speaker B have equal status or position, and they are already accustomed to communicating with each other.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 8:\n",
      "Role A: Cleaning staff at school\n",
      "Role B: Teacher at school\n",
      "Context: Speaker A informs speaker B that the book from speaker B has been returned by him to the office. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 9:\n",
      "Role A: Doctor\n",
      "Role B: Patient\n",
      "Context: Speaker A asked speaker B about the condition of the back of speaker B's head. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 10:\n",
      "Role A: Classmate\n",
      "Role B: Classmate\n",
      "Context: Speaker A asked when Speaker B would go home. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 11:\n",
      "Role A: Batchmate\n",
      "Role B: Batchmate\n",
      "Context: Speaker A tells speaker B that the father of speaker B met him yesterday.  Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 12:\n",
      "Role A: Schoolmate\n",
      "Role B: Schoolmate\n",
      "Context: The speaker talked with his schoolmates at a reunion event. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 13:\n",
      "Role A: Project partner\n",
      "Role B: Project partner\n",
      "Context: Speaker A asked about the teaching place from Speaker B's mother who is a teacher, Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Wah, cedhak karo omahku kuwi. Mapel opo sing diajarke?` (Wow, that's close\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 14:\n",
      "Role A: Close friend\n",
      "Role B: Close friend\n",
      "Context: Speaker A asks for souvenirs from speaker B, but speaker B forgets to bring souvenirs to speaker A. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Halah, ngapurane. Padahal aku\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 15:\n",
      "Role A: Close friend since elementary school\n",
      "Role B: Close friend since elementary school\n",
      "Context: Speaker A invited speaker B to go to Jogja, but speaker B could not do it now. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 16:\n",
      "Role A: Old friend\n",
      "Role B: Old friend\n",
      "Context: Speaker A asked Speaker B about the return of Speaker B's father from Sumatra. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Wah, syukur. Gimana kabare beliau? Sehat? (Wow, thank goodness. How is he?\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 17:\n",
      "Role A: Workmate of the same age\n",
      "Role B: Workmate of the same age\n",
      "Context: Speaker A tells speaker B to wake up their friend who is next to speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 18:\n",
      "Role A: A friend who has been known for 10 years\n",
      "Role B: A friend who has been known for 10 years\n",
      "Context: Speaker A invited speaker B to work in the factory, but speaker B refused. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 19:\n",
      "Role A: Childhood friend\n",
      "Role B: Childhood friend\n",
      "Context: Speaker A asks speaker B about past events where speaker A often tells speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 20:\n",
      "Role A: Campus friend\n",
      "Role B: Campus friend\n",
      "Context: Speaker A asked about the assignment given by the lecturer to speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 21:\n",
      "Role A: The friend being visited\n",
      "Role B: The friend who is visiting\n",
      "Context: Speaker A offers a drink to speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Ono, ono. Tak gawekne sek. Gula piro? (Yes, I do. I\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 22:\n",
      "Role A: Class president\n",
      "Role B: Class member\n",
      "Context: Speaker A asked speaker B about the place where speaker A put the document yesterday. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Iya, sing kuwi. Kok weruh? (Yes, that one. How did you know\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 23:\n",
      "Role A: Military school training commander\n",
      "Role B: Military school cadet\n",
      "Context: Speaker A told speaker B to go to Semarang for training and speaker B accepted. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Priksa manawa kabeh perlengkapan wis cemepak. Aja lali gawanen seragam lengkap lan peralatan pribadimu. (Make sure all your equipment is complete. Don't forget to bring\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 24:\n",
      "Role A: Batch leader\n",
      "Role B: Batch member\n",
      "Context: Speaker A tells speaker B to distribute gifts to each class leader. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Yo, ojo lali. Ben cepet rampung urusane.` (Yeah, don't forget. So that the task finishes\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 25:\n",
      "Role A: Student council president\n",
      "Role B: Student council secretary\n",
      "Context: Speaker A asked about the assignment he gave to speaker B yesterday. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 26:\n",
      "Role A: School principal\n",
      "Role B: Student\n",
      "Context: Speaker A asked about speaker B who was visited by people from the education office. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: Lho, ana apa ta kok kowe sing dipilih? (Why, what happened\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 27:\n",
      "Role A: Football team member\n",
      "Role B: Football team member\n",
      "Context: Speaker A tells speaker B not to play roughly. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Heh, kalem men main\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 28:\n",
      "Role A: School student\n",
      "Role B: Cleaning staff at school\n",
      "Context: Speaker A asks speaker B to sit for a while and take a break in the sweep. Speaker B has a higher status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 29:\n",
      "Role A: Football team captain\n",
      "Role B: Football team member\n",
      "Context: Speaker A asks speaker B about what the coach told speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 30:\n",
      "Role A: Grandfather\n",
      "Role B: Grandchild\n",
      "Context: Speaker A gives pocket money to speaker B to provide for going to school. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Iyo, sing sregep sinaune. Aja dolan wae. (Yes, study diligently. Don't just play.)\n",
      "Utterance B: Inggih, Mbah. Kula badhe sregep sinau\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 31:\n",
      "Role A: Grandmother\n",
      "Role B: Grandchild\n",
      "Context: Speaker A asked about the day of Speaker B's return to Jakarta. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Oh, Minggu. Yo wis, ati-ati yo le. Nggawa oleh-oleh ojo lali. (Oh, Sunday. Alright, be careful, child. Don't forget to bring souvenirs.)\n",
      "Utterance B: Inggih, Mbah. Mbah\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 32:\n",
      "Role A: Father\n",
      "Role B: Child\n",
      "Context: Speaker A asks speaker B to take his cup from the kitchen. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 33:\n",
      "Role A: Mother\n",
      "Role B: Child\n",
      "Context: Speaker A shows a small photo of herself during dance practice to speaker B. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: â€œHe eh, lha piye meneh. Wi\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 34:\n",
      "Role A: Uncle\n",
      "Role B: Nephew\n",
      "Context: Speaker A asked about the herbal medicine drunk by the father of speaker B. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: Oh, beras kencur. Kanggo opo ngombe jamu\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 35:\n",
      "Role A: Aunt\n",
      "Role B: Nephew\n",
      "Context: Speaker A asks Speaker B about the permission for them to go together which is proposed to Speaker B's father. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Bud\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 36:\n",
      "Role A: Cousin\n",
      "Role B: Cousin\n",
      "Context: Speaker A asked about the number of children owned by buffaloes from speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 37:\n",
      "Role A: Coach\n",
      "Role B: Pupil\n",
      "Context: Speaker A advised speaker B to play football more boldly. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Lepat kuwi\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 38:\n",
      "Role A: Boarding house owner\n",
      "Role B: Boarding house tenant\n",
      "Context: Speaker A reminded speaker B not to leave any of his belongings in the boarding house. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 39:\n",
      "Role A: A person who is 30 years older\n",
      "Role B: A person who is 30 years younger\n",
      "Context: Speaker A asked about Speaker B's yard which seemed to have never been cleaned. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Lha piye ta? Wong\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 40:\n",
      "Role A: A person who is 20 years older\n",
      "Role B: A person who is 20 years younger\n",
      "Context: Speaker A asked speaker B about the work of friends of speaker B. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 41:\n",
      "Role A: A person who is 10 years older\n",
      "Role B: A person who is 10 years younger\n",
      "Context: Speaker A asked speaker B about the location of his handkerchief. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Iya, sing tak gawa wingi. (Yes, the one I brought yesterday.)\n",
      "Utterance B: Kula mboten ngertos, Pak/Bu. Mboten nate ningali. (I\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 42:\n",
      "Role A: Uncle\n",
      "Role B: Nephew\n",
      "Context: Speaker A asked about the purpose of leaving speaker B because he saw the fishing hook brought by speaker B. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Wah, kepriye kabare iwak-iwake saiki? Akeh apa ora? (\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 43:\n",
      "Role A: Biological older sibling\n",
      "Role B: Biological younger sibling\n",
      "Context: Speaker A brought goat blended food to speaker B and asked if his sister had eaten or not. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 44:\n",
      "Role A: An older person in the surrounding environment\n",
      "Role B: A younger person in the surrounding environment\n",
      "Context: Speaker A asked if Speaker B did not hear the call to prayer that had resounded. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 45:\n",
      "Role A: Same-age cousin\n",
      "Role B: Same-age cousin\n",
      "Context: Speaker A asked about the return of the father from speaker B. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 46:\n",
      "Role A: Close friend\n",
      "Role B: Close friend\n",
      "Context: Speaker A asks speaker B if they will go with a friend of speaker B or not. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Yo kui lho, sing wingi crita-crita kae.` (You know, the one you were talking about the other day.)\n",
      "Utterance B: Oh, si X? Iyo melu. Kenapa ta kok takon?\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 47:\n",
      "Role A: Older cousin\n",
      "Role B: Younger cousin\n",
      "Context: Speaker A asked speaker B whether the jathilan art in the south of the village had been completed or not. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 48:\n",
      "Role A: Friend\n",
      "Role B: Friend\n",
      "Context: Speaker A asked about his first place of play with speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 49:\n",
      "Role A: Study group partner\n",
      "Role B: Study group partner\n",
      "Context: Speaker A asks if speaker B has studied for tomorrow's test. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 50:\n",
      "Role A: Student\n",
      "Role B: Teacher\n",
      "Context: Speaker A asks the current teaching location from speaker B. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 51:\n",
      "Role A: Peer\n",
      "Role B: Peer\n",
      "Context: Speaker A tells speaker B to wake up his friend who is next to him because the Friday sermon has been completed. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 52:\n",
      "Role A: Coworker\n",
      "Role B: Coworker\n",
      "Context: Speaker A asked if speaker B was sick yesterday so he did not go to work. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Mosok, wingi lara ta kok ora teko kerja? (Really? Were you sick yesterday, why didn't you come to work?)\n",
      "Utterance B: I\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 53:\n",
      "Role A: Same-age neighbor\n",
      "Role B: Same-age neighbor\n",
      "Context: Speaker A offers the food he is making to speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Wah, sayur lodeh! Seneng aku. Tapi\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 54:\n",
      "Role A: Student\n",
      "Role B: Teacher\n",
      "Context: Speaker A asked why Speaker B had only been silent since earlier. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 55:\n",
      "Role A: Nephew\n",
      "Role B: Father's older brother\n",
      "Context: Speaker A asks speaker B if his grandfather has woken up or not. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 56:\n",
      "Role A: Subordinate\n",
      "Role B: Superior\n",
      "Context: Speaker A asked speaker B about who would take care of the goods held by him. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 57:\n",
      "Role A: The general public\n",
      "Role B: Official\n",
      "Context: Speaker A asked if Speaker B would make a new policy. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: Ngaten, Pak/Bu. Menika bab kebijakan ingkang sampun dangu, punapa badhe wonten\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model1_noHint_A, model1_noHint_B = evaluate_model(model1, tokenizer1, data, False)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model2_noHint_A, model2_noHint_B = evaluate_model(model2, tokenizer2, data, False)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model3_noHint_A, model3_noHint_B = evaluate_model(model3, tokenizer3, data, False)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# model6_noHint_A, model6_noHint_B = evaluate_model(model6, tokenizer6, data, False)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# modelOpenAI_noHint_A, modelOpenAI_noHint_B = evaluate_api_model(data, 'openai', False)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m modelGemini_noHint_A, modelGemini_noHint_B \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_api_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgemini\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 60\u001b[0m, in \u001b[0;36mevaluate_api_model\u001b[0;34m(data, model_type, hint)\u001b[0m\n\u001b[1;32m     57\u001b[0m     decoded_output \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Gemini\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerationConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     decoded_output \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Initialize variables for tracking occurrences\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/grpc/_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[0;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1_noHint_A, model1_noHint_B = evaluate_model(model1, tokenizer1, data, False)\n",
    "model2_noHint_A, model2_noHint_B = evaluate_model(model2, tokenizer2, data, False)\n",
    "model3_noHint_A, model3_noHint_B = evaluate_model(model3, tokenizer3, data, False)\n",
    "model4_noHint_A, model4_noHint_B = evaluate_model(model4, tokenizer4, data, False)\n",
    "model5_noHint_A, model5_noHint_B = evaluate_model(model5, tokenizer5, data, False)\n",
    "model6_noHint_A, model6_noHint_B = evaluate_model(model6, tokenizer6, data, False)\n",
    "modelOpenAI_noHint_A, modelOpenAI_noHint_B = evaluate_api_model(data, 'openai', False)\n",
    "modelGemini_noHint_A, modelGemini_noHint_B = evaluate_api_model(data, 'gemini', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e085d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 1:\n",
      "Role A: Teacher\n",
      "Role B: Student\n",
      "Context: Speaker A asked speaker B about what he had eaten today.  Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Hey, what have you eaten today?\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 2:\n",
      "Role A: Peer\n",
      "Role B: Peer\n",
      "Context: Speaker A asks speaker B about what Speaker B's father ate today. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Bapakmu dhahar napa dina iki, Le? (Your father ate what today, dude?)\n",
      "Utterance B: Dhahar sega pecel kali\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 3:\n",
      "Role A: Older sibling\n",
      "Role B: Younger sibling\n",
      "Context: Speaker A asks speaker B about what Speaker B learned at school today. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: Lha, basa Jawine sinau apa? (Ngoko)\n",
      "Utterance B: Sinau babagan aksara Jawa, Mas.  (Krama Alus)\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 4:\n",
      "Role A: A friend from the same village who has not met each other for a long time\n",
      "Role B: A friend from the same village who has not met each other for a long time\n",
      "Context: Speaker A asks speaker B about the news from speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 5:\n",
      "Role A: The school canteen attendant.\n",
      "Role B: Students at school\n",
      "Context: Speaker A asks speaker B about the university he is going to. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 6:\n",
      "Role A: People who do not know each other\n",
      "Role B: People who do not know each other\n",
      "Context: Speaker A asked speaker B about the direction to Gadjah Mada University. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 7:\n",
      "Role A: Colleague (lecturer)\n",
      "Role B: Colleague (lecturer)\n",
      "Context: Speaker A asked speaker B about the number of students who entered the Javanese literature department. Speaker A and Speaker B have equal status or position, and they are already accustomed to communicating with each other.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 8:\n",
      "Role A: Cleaning staff at school\n",
      "Role B: Teacher at school\n",
      "Context: Speaker A informs speaker B that the book from speaker B has been returned by him to the office. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 9:\n",
      "Role A: Doctor\n",
      "Role B: Patient\n",
      "Context: Speaker A asked speaker B about the condition of the back of speaker B's head. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 10:\n",
      "Role A: Classmate\n",
      "Role B: Classmate\n",
      "Context: Speaker A asked when Speaker B would go home. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Le\n",
      "Utterance B: Jam loro, Coy\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 11:\n",
      "Role A: Batchmate\n",
      "Role B: Batchmate\n",
      "Context: Speaker A tells speaker B that the father of speaker B met him yesterday.  Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 12:\n",
      "Role A: Schoolmate\n",
      "Role B: Schoolmate\n",
      "Context: The speaker talked with his schoolmates at a reunion event. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Ngeneki kerjo neng endi saiki\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 13:\n",
      "Role A: Project partner\n",
      "Role B: Project partner\n",
      "Context: Speaker A asked about the teaching place from Speaker B's mother who is a teacher, Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Durung. Kepengin mrana kapan-kapan. Ibuke guru mapel apa ta? (Not yet. Want to go there sometime. Your mother teaches what subject\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 14:\n",
      "Role A: Close friend\n",
      "Role B: Close friend\n",
      "Context: Speaker A asks for souvenirs from speaker B, but speaker B forgets to bring souvenirs to speaker A. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: â€œHalah, kowe ki piye ta? Wis dikandhani disangoni kok malah lali.â€\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 15:\n",
      "Role A: Close friend since elementary school\n",
      "Role B: Close friend since elementary school\n",
      "Context: Speaker A invited speaker B to go to Jogja, but speaker B could not do it now. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 16:\n",
      "Role A: Old friend\n",
      "Role B: Old friend\n",
      "Context: Speaker A asked Speaker B about the return of Speaker B's father from Sumatra. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Pakâ€™e wis mulih saka Sumatra apa urung,\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 17:\n",
      "Role A: Workmate of the same age\n",
      "Role B: Workmate of the same age\n",
      "Context: Speaker A tells speaker B to wake up their friend who is next to speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 18:\n",
      "Role A: A friend who has been known for 10 years\n",
      "Role B: A friend who has been known for 10 years\n",
      "Context: Speaker A invited speaker B to work in the factory, but speaker B refused. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 19:\n",
      "Role A: Childhood friend\n",
      "Role B: Childhood friend\n",
      "Context: Speaker A asks speaker B about past events where speaker A often tells speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: â€œOalah, iyo! Hahahaha. K\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 20:\n",
      "Role A: Campus friend\n",
      "Role B: Campus friend\n",
      "Context: Speaker A asked about the assignment given by the lecturer to speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 21:\n",
      "Role A: The friend being visited\n",
      "Role B: The friend who is visiting\n",
      "Context: Speaker A offers a drink to speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Teh, kopi, jus jeruk. Kae lho ning kulkas, njupuk dewe wae ya.` (Tea, coffee, orange juice. It's in the fridge, help yourself.)\n",
      "Utterance B: Yo wes, aku jus jeruk ae yo. Maturnuwun.\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 22:\n",
      "Role A: Class president\n",
      "Role B: Class member\n",
      "Context: Speaker A asked speaker B about the place where speaker A put the document yesterday. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 23:\n",
      "Role A: Military school training commander\n",
      "Role B: Military school cadet\n",
      "Context: Speaker A told speaker B to go to Semarang for training and speaker B accepted. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: KowÃ© wis nyawisake kabeh perlengkapan sing dibutuhake? Aja nganti ana sing ketinggalan.` (Have you prepared all the necessary equipment? Don'\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 24:\n",
      "Role A: Batch leader\n",
      "Role B: Batch member\n",
      "Context: Speaker A tells speaker B to distribute gifts to each class leader. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Bro, kado-kadone dibagi nang ketua kelas kabeh yo.` (Bro, distribute the gifts to all the class leaders, okay?)\n",
      "Utterance B: Oke,\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 25:\n",
      "Role A: Student council president\n",
      "Role B: Student council secretary\n",
      "Context: Speaker A asked about the assignment he gave to speaker B yesterday. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Wah, cepet yo. Tak kira butuh wektu luwih suwe. (Wow, that's fast\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 26:\n",
      "Role A: School principal\n",
      "Role B: Student\n",
      "Context: Speaker A asked about speaker B who was visited by people from the education office. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: Ono opo, le? Ceritaa kene.\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 27:\n",
      "Role A: Football team member\n",
      "Role B: Football team member\n",
      "Context: Speaker A tells speaker B not to play roughly. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 28:\n",
      "Role A: School student\n",
      "Role B: Cleaning staff at school\n",
      "Context: Speaker A asks speaker B to sit for a while and take a break in the sweep. Speaker B has a higher status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 29:\n",
      "Role A: Football team captain\n",
      "Role B: Football team member\n",
      "Context: Speaker A asks speaker B about what the coach told speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Aku yo podo. Ndak digatekne ki opo? (Me too.  Was anything emphasized?)\n",
      "Utterance B: Disuruh latihan terus ben pas pertandhingan ora grogi. Kowe yo mesthi yo to?\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 30:\n",
      "Role A: Grandfather\n",
      "Role B: Grandchild\n",
      "Context: Speaker A gives pocket money to speaker B to provide for going to school. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 31:\n",
      "Role A: Grandmother\n",
      "Role B: Grandchild\n",
      "Context: Speaker A asked about the day of Speaker B's return to Jakarta. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Nak, kapan bali Jakarta? (Krama - Child, when will you return to Jakarta?)\n",
      "Utterance B: Minggu ngajeng, Eyang. (Ngoko Alus - Next Sunday,\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 32:\n",
      "Role A: Father\n",
      "Role B: Child\n",
      "Context: Speaker A asks speaker B to take his cup from the kitchen. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 33:\n",
      "Role A: Mother\n",
      "Role B: Child\n",
      "Context: Speaker A shows a small photo of herself during dance practice to speaker B. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 34:\n",
      "Role A: Uncle\n",
      "Role B: Nephew\n",
      "Context: Speaker A asked about the herbal medicine drunk by the father of speaker B. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 35:\n",
      "Role A: Aunt\n",
      "Role B: Nephew\n",
      "Context: Speaker A asks Speaker B about the permission for them to go together which is proposed to Speaker B's father. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Bapakmu nglilani, ananging kowe kudu\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 36:\n",
      "Role A: Cousin\n",
      "Role B: Cousin\n",
      "Context: Speaker A asked about the number of children owned by buffaloes from speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 37:\n",
      "Role A: Coach\n",
      "Role B: Pupil\n",
      "Context: Speaker A advised speaker B to play football more boldly. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 38:\n",
      "Role A: Boarding house owner\n",
      "Role B: Boarding house tenant\n",
      "Context: Speaker A reminded speaker B not to leave any of his belongings in the boarding house. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: Hey, don't forget to take all your belongings from your room, okay?\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 39:\n",
      "Role A: A person who is 30 years older\n",
      "Role B: A person who is 30 years younger\n",
      "Context: Speaker A asked about Speaker B's yard which seemed to have never been cleaned. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 40:\n",
      "Role A: A person who is 20 years older\n",
      "Role B: A person who is 20 years younger\n",
      "Context: Speaker A asked speaker B about the work of friends of speaker B. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 41:\n",
      "Role A: A person who is 10 years older\n",
      "Role B: A person who is 10 years younger\n",
      "Context: Speaker A asked speaker B about the location of his handkerchief. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 42:\n",
      "Role A: Uncle\n",
      "Role B: Nephew\n",
      "Context: Speaker A asked about the purpose of leaving speaker B because he saw the fishing hook brought by speaker B. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 43:\n",
      "Role A: Biological older sibling\n",
      "Role B: Biological younger sibling\n",
      "Context: Speaker A brought goat blended food to speaker B and asked if his sister had eaten or not. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 44:\n",
      "Role A: An older person in the surrounding environment\n",
      "Role B: A younger person in the surrounding environment\n",
      "Context: Speaker A asked if Speaker B did not hear the call to prayer that had resounded. Speaker B has a lower status or position than Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 45:\n",
      "Role A: Same-age cousin\n",
      "Role B: Same-age cousin\n",
      "Context: Speaker A asked about the return of the father from speaker B. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 46:\n",
      "Role A: Close friend\n",
      "Role B: Close friend\n",
      "Context: Speaker A asks speaker B if they will go with a friend of speaker B or not. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Kowe sesuk tekan karo kancane kuwi po ora?` (Are you going with that friend of yours tomorrow or\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 47:\n",
      "Role A: Older cousin\n",
      "Role B: Younger cousin\n",
      "Context: Speaker A asked speaker B whether the jathilan art in the south of the village had been completed or not. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 48:\n",
      "Role A: Friend\n",
      "Role B: Friend\n",
      "Context: Speaker A asked about his first place of play with speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Aku yo ning lapangan, nanging liyane. Ning lapangan cedhak se\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 49:\n",
      "Role A: Study group partner\n",
      "Role B: Study group partner\n",
      "Context: Speaker A asks if speaker B has studied for tomorrow's test. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Kowe wis sinau durung kanggo tes sesuk?` (Have you studied yet for tomorrow's test?)\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 50:\n",
      "Role A: Student\n",
      "Role B: Teacher\n",
      "Context: Speaker A asks the current teaching location from speaker B. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 51:\n",
      "Role A: Peer\n",
      "Role B: Peer\n",
      "Context: Speaker A tells speaker B to wake up his friend who is next to him because the Friday sermon has been completed. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 52:\n",
      "Role A: Coworker\n",
      "Role B: Coworker\n",
      "Context: Speaker A asked if speaker B was sick yesterday so he did not go to work. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 53:\n",
      "Role A: Same-age neighbor\n",
      "Role B: Same-age neighbor\n",
      "Context: Speaker A offers the food he is making to speaker B. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Aku lagi masak sayur lodeh thok. Lha wong mung dewekan. Yen kowe gelem, melu mangan opore\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 54:\n",
      "Role A: Student\n",
      "Role B: Teacher\n",
      "Context: Speaker A asked why Speaker B had only been silent since earlier. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 55:\n",
      "Role A: Nephew\n",
      "Role B: Father's older brother\n",
      "Context: Speaker A asks speaker B if his grandfather has woken up or not. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 56:\n",
      "Role A: Subordinate\n",
      "Role B: Superior\n",
      "Context: Speaker A asked speaker B about who would take care of the goods held by him. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 57:\n",
      "Role A: The general public\n",
      "Role B: Official\n",
      "Context: Speaker A asked if Speaker B would make a new policy. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 58:\n",
      "Role A: Grandchild\n",
      "Role B: Grandfather\n",
      "Context: Speaker A asked speaker B if his grandmother was still bathing or not. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 59:\n",
      "Role A: Grandchild\n",
      "Role B: Grandmother\n",
      "Context: Speaker A gives him speaker B's glasses. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 60:\n",
      "Role A: Child\n",
      "Role B: Father\n",
      "Context: Speaker A informs speaker B that a guest is coming. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: **Nuwun sewu, Bapak. Wonten tamu rawuh.** (Excuse me, Father\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 61:\n",
      "Role A: Child\n",
      "Role B: Mother\n",
      "Context: Speaker A offers new slippers to speaker B. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: â€œKula tumbasaken wonten pasar kaliyan Bapak, Buk. (I\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 62:\n",
      "Role A: Nephew\n",
      "Role B: Uncle\n",
      "Context: Speaker A asked if speaker B had clurite that was still in good condition. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 63:\n",
      "Role A: Nephew\n",
      "Role B: Aunt\n",
      "Context: Speaker A asked if speaker B had cooked rice or not. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 64:\n",
      "Role A: Student\n",
      "Role B: Lecturer\n",
      "Context: Speaker A asked if he could meet speaker B after finishing college. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: Kula badhe tanglet babagan materi ingkang\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 65:\n",
      "Role A: Student\n",
      "Role B: Professor\n",
      "Context: Speaker A offers to show the exit direction to speaker B. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 66:\n",
      "Role A: Villager\n",
      "Role B: Religious leader\n",
      "Context: Speaker A asked why Speaker B had not attended a religious event in the village for a long time. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 67:\n",
      "Role A: The general public\n",
      "Role B: Regent\n",
      "Context: Speaker A asks speaker B whether the letter he wrote has been read or not. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 68:\n",
      "Role A: The general public\n",
      "Role B: Governor\n",
      "Context: Speaker A asked about the vehicle that Speaker B was riding in when heading to the location. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 69:\n",
      "Role A: The general public\n",
      "Role B: Community leaders\n",
      "Context: Speaker A offers herbal medicine if speaker B still feels pain in his stomach. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 70:\n",
      "Role A: Student\n",
      "Role B: Professor\n",
      "Context: Speaker A asked Speaker B for his opinion on whether it is better to take a S3 in Europe or America to Speaker B. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: Kula nggadhahi rencana badhÃ© nglajengaken kuliah S\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 71:\n",
      "Role A: Members of the youth organization\n",
      "Role B: Youth organization elders\n",
      "Context: Speaker A asked if the documents he gave yesterday to Speaker B had been submitted to Mr. RT. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 72:\n",
      "Role A: Art enthusiasts\n",
      "Role B: Older artists\n",
      "Context: Speaker A praised the painting made by speaker B. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 73:\n",
      "Role A: The general public\n",
      "Role B: Mayor\n",
      "Context: Speaker A praised Speaker B's expensive clothes. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: (K\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 74:\n",
      "Role A: Law students\n",
      "Role B: Judge\n",
      "Context: Speaker A emphasized that the victim of the case had died to speaker B. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 75:\n",
      "Role A: Assistant lecturer\n",
      "Role B: Lecturer\n",
      "Context: Speaker A asked if Speaker B had checked the assignments he collected yesterday. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 76:\n",
      "Role A: Forum members\n",
      "Role B: Forum chairs\n",
      "Context: Speaker A advises Speaker B not to scold other forum members. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 77:\n",
      "Role A: Presidential aide\n",
      "Role B: President\n",
      "Context: Speaker A gave a drink of wedang uwuh to speaker B. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: Mboten usah repot-repot, Pak. Menawi kirang legi, wonten gula pasir ing meja.\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 78:\n",
      "Role A: Wife\n",
      "Role B: Husband\n",
      "Context: Speaker A asked if there was anything in the heart of speaker B. Speaker A has a lower status or position than Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 79:\n",
      "Role A: Stranger\n",
      "Role B: Stranger\n",
      "Context: Speaker A greets Speaker B, who is a stranger of the same age. Speaker A and Speaker B have equal status but want to show mutual respect to each other.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 80:\n",
      "Role A: Echelon 2 official (Director)\n",
      "Role B: Echelon 1 official (Director General)\n",
      "Context: Speaker A asking Speaker B about the meeting results. Speaker B has a higher status than Speaker A, but Speaker B still shows respect to Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 81:\n",
      "Role A: Echelon 2 official (Director)\n",
      "Role B: Echelon 2 official (Director)\n",
      "Context: Speaker A and B are having a formal discussion about policy. Speaker A and Speaker B have equal status or position, and they are already accustomed to communicating with each other, , yet both still show mutual highly respect toward one another.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 82:\n",
      "Role A: prospective son-in-law\n",
      "Role B: future father-in-law\n",
      "Context: Speaker A is speaking to Speaker B talking about Wedding Ceremony. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 83:\n",
      "Role A: Student\n",
      "Role B: A lecturer\n",
      "Context: Speaker A is telling to Speaker B about the result of assignment grading task. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: Niki, Pak, asiling koreksi tugas saking mahasiswa.\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 84:\n",
      "Role A: Citizen\n",
      "Role B: Head of Village\n",
      "Context: Speaker A is requesting information from Speaker B about the poverty certificate that he has submitted for signature. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 85:\n",
      "Role A: Daughter\n",
      "Role B: Mother\n",
      "Context: Speaker A is asking about the possibility of Speaker B going to the city. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: Menika, Ibu badhe tindak dhateng kutha menapa mboten nggih?  (Um, are you going to the city, Mother?)\n",
      "Utterance B: Iya, le. Besok Ibu arep menyang kutha. Ana perlu\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 86:\n",
      "Role A: Nephew\n",
      "Role B: Uncle\n",
      "Context: Speaker A is asking Speaker B whether the bicycle has been repaired or not. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 87:\n",
      "Role A: Buyer\n",
      "Role B: Seller (He is much older than the buyer)\n",
      "Context: Speaker A is asking Speaker B about the price at the market. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: Wah, larang nggih, Pak.  Saget kirang mboten nggih? (Wow, that's expensive,\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 88:\n",
      "Role A: Brother-in-law (at the same age)\n",
      "Role B: Brother-in-law (at the same age)\n",
      "Context: Speaker A is talking about hisplan to go to Speaker Bâ€™s house. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: â€œOra ono opo-opo sih, pengen ngobrol-ngobrol karo kowe wae. Wis suwe ra ketemu.â€ (Nothing really, just want to chat with you.\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 89:\n",
      "Role A: residents of the housing complex (neighbor)\n",
      "Role B: residents of the housing complex (neighbor)\n",
      "Context: Speaker A is discussing waste management with Speaker B in their residential complex. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Oalah, p\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 90:\n",
      "Role A: residents of the housing complex (neighbor)\n",
      "Role B: residents of the housing complex (neighbor) - older\n",
      "Context: Speaker A is talking to Speaker B about the quality of waste management in their housing complex. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 91:\n",
      "Role A: Sister\n",
      "Role B: Old Brother\n",
      "Context: Speaker A asked and requested help from Speaker B if he could take her to campus or not. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 92:\n",
      "Role A: Daughter\n",
      "Role B: Mother\n",
      "Context: Speaker A is asking Speaker B what food she wants to eat. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: Inggih, melu Bu.  (Yes, I will join you, Mother.)\n",
      "Utterance B: Ya wis, gek ndang pesenke. (Alright, then quickly order it.)\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 93:\n",
      "Role A: Head of Village\n",
      "Role B: Citizen\n",
      "Context: Speaker A is speaking to the entire audience regarding the importance of disposing of trash in the designated places, but Speaker B responds with his argument about why he does not dispose of trash in the designated places.. Speaker A and Speaker B have equal status or position, and they are already accustomed to communicating with each other, , yet both still show mutual highly respect toward one another.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 94:\n",
      "Role A: Student\n",
      "Role B: Head of School\n",
      "Context: Speaker A is asking Speaker B about the location of the ceremony. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 95:\n",
      "Role A: Village Secretary\n",
      "Role B: Citizen\n",
      "Context: Speaker A is giving a speech to the residents about the possibility of not holding the August 17th competition due to the village's budget constraints, but one of the residents, Speaker B, expresses a willingness to fund the event. Speaker A and Speaker B have equal status or position, and they are already accustomed to communicating with each other, , yet both still show mutual highly respect toward one another.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 96:\n",
      "Role A: Old Sister\n",
      "Role B: Sister\n",
      "Context: Speaker A advises Speaker B not to come home late at night. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 97:\n",
      "Role A: Police officer\n",
      "Role B: a little child\n",
      "Context: Speaker A is asking Speaker B, who is about to cross the street alone. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Wong tuwamu endi, Le?` (Where are your parents, child?) - Ngoko Alus (\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 98:\n",
      "Role A: Best Friend\n",
      "Role B: Best Friend\n",
      "Context: Speaker A is discussing with Speaker B what genre of songs will be sung at the event to be held in the village. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Aku kepikiran pop karo dangdut wae, ben sing enom-\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 99:\n",
      "Role A: Best Friend\n",
      "Role B: Best Friend\n",
      "Context: Speaker A is asking Speaker B for help with servicing his broken motorcycle. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 100:\n",
      "Role A: Fellow Neighbor\n",
      "Role B: Fellow Neighbor (Younger)\n",
      "Context: Speaker A is asking Speaker B to move the car that is parked in front of Speaker A's house. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 101:\n",
      "Role A: Friend\n",
      "Role B: Friend\n",
      "Context: Speaker A is apologizing to Speaker B for not being able to attend Speaker A's wedding. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Iki lho, anake lara dadakan. Kudu tak gowo nang dokter.` (This, you see, my\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 102:\n",
      "Role A: an Adult\n",
      "Role B: a little child\n",
      "Context: Speaker A is asking Speaker B if he can tie his shoes or not, and then offers assistance and advice. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: Loh, kok durung isa? Wis gedhe lho kowe.  (Ngoko Alus - Oh, why not yet? You're already big, you know.)\n",
      "Utterance B: Angel, Pakdhe.  (Krama - It'\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 103:\n",
      "Role A: a college in the office\n",
      "Role B: a college in the office\n",
      "Context: Speaker A is giving criticism to Speaker B regarding the work report. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 104:\n",
      "Role A: a college in the office\n",
      "Role B: a college in the office\n",
      "Context: Speaker A congratulates Speaker B on his new position and asks when he will be moving. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 105:\n",
      "Role A: A Friend\n",
      "Role B: A Friend\n",
      "Context: Speaker A is informing that he will be holding a birthday party and is asking if Speaker B can come on the day of the celebration. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Dina Sabtu, awan. Jam siji awan nganti sore.\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 106:\n",
      "Role A: A Friend\n",
      "Role B: A Friend\n",
      "Context: Speaker A is protesting against Speaker B for allegedly leaving scissors on the floor. Speaker A is a bit angry because the scissors pose a danger to small children. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 107:\n",
      "Role A: A son\n",
      "Role B: Father\n",
      "Context: Speaker A is asking Speaker B not to use the car when driving him to school because he is afraid of being teased by his friends. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 108:\n",
      "Role A: subordinate\n",
      "Role B: Supervisor\n",
      "Context: Speaker A is asking Speaker B about the composition of the materials for the road that he will be working on. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 109:\n",
      "Role A: Student\n",
      "Role B: Teacher\n",
      "Context: Speaker A is asking Speaker B whether the Javanese language assignment should be submitted on Tuesday or Thursday. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 110:\n",
      "Role A: Daughter\n",
      "Role B: Mother\n",
      "Context: Speaker A is asking Speaker B if she could help her translate her Indonesian homework. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 111:\n",
      "Role A: Student\n",
      "Role B: Teacher\n",
      "Context: Speaker A is apologizing to Speaker B for not being able to attend class the day before due to illness. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 112:\n",
      "Role A: A son\n",
      "Role B: Father\n",
      "Context: Speaker A is apologizing to Speaker B for failing the entrance exam for the university he wanted. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: Kula nyuwun pangapunten, Pak.  Tes mlebet universitas ingkang kula incer mboten saged kula lampahi kanthi sae. Kula mboten lulus. (I apologize, Father. I couldn't do well in the entrance exam for the university I was aiming for. I\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 113:\n",
      "Role A: A Resident in the housing complex\n",
      "Role B: Chairman of the Neighborhood Association\n",
      "Context: Speaker A is expressing objections to Speaker B regarding the increase in the monthly fees in the housing complex. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 114:\n",
      "Role A: Master of Ceremony\n",
      "Role B: a distinguished guest\n",
      "Context: Speaker A is announcing to all the invited guests to enjoy the food in a designated area. Additionally, Speaker A informs Speaker B to go up on stage for a photo session. Speaker A and Speaker B have equal status or position, and they are already accustomed to communicating with each other, , yet both still show mutual highly respect toward one another.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 115:\n",
      "Role A: Fellow Neighbor\n",
      "Role B: Fellow Neighbor (Younger)\n",
      "Context: Speaker A expresses condolences to Speaker B. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another. \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 116:\n",
      "Role A: Fellow Neighbor\n",
      "Role B: Fellow Neighbor (Younger)\n",
      "Context: Speaker A is inviting Speaker B to attend the celebration party that will be held because his child has passed the college entrance exam.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 117:\n",
      "Role A: Student\n",
      "Role B: Teacher\n",
      "Context: Speaker A greets Speaker B and asks about the shirt that Speaker B is wearing. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another. \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 118:\n",
      "Role A: Little Sister\n",
      "Role B: Old Brother\n",
      "Context: Speaker A is asking Speaker B whether he will have breakfast before going to the office or not. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 119:\n",
      "Role A: Grandchild\n",
      "Role B: Grandmother\n",
      "Context: Speaker A is asking Speaker B whether she is going to Surabaya or Bandung. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: Menawi Mbah Putri, badhe tindak dhateng Surabaya menapa Bandung nggih? (\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 120:\n",
      "Role A: A son\n",
      "Role B: Father\n",
      "Context: Speaker A is asking for Speaker B's blessing to get married. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 121:\n",
      "Role A: A son\n",
      "Role B: Grandfather\n",
      "Context: Speaker A is asking for Speaker B's blessing to get married. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 122:\n",
      "Role A: High ranking public officials\n",
      "Role B: High ranking public officials\n",
      "Context: Speaker A is discussing with Speaker B the government's policy regarding the Free Lunch Program. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another. \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 123:\n",
      "Role A: A citizen\n",
      "Role B: Head of Village\n",
      "Context: Speaker A is asking Speaker B to provide input regarding the community meal event. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 124:\n",
      "Role A: MC\n",
      "Role B: High ranking public officials\n",
      "Context: Speaker A honors Speaker B, who is the guest of honor at the formal event. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another. \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 125:\n",
      "Role A: Son\n",
      "Role B: Father\n",
      "Context: Speaker A invites Speaker B to attend the celebration of his child's graduation. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 126:\n",
      "Role A: nephew\n",
      "Role B: Uncle\n",
      "Context: Speaker A invites Speaker B to attend the family gathering. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 127:\n",
      "Role A: Fellow Neighbor\n",
      "Role B: Fellow Neighbor (older)\n",
      "Context: Speaker A invites Speaker B to attend the thanksgiving event. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 128:\n",
      "Role A: Supervisor\n",
      "Role B: Subordinate (Older)\n",
      "Context: Speaker A advises and asks Speaker B regarding the confidential information that was accidentally disclosed to someone who is not an office employee. Speaker A has a higher status than Speaker B, but Speaker A still shows respect to Speaker B.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 129:\n",
      "Role A: Citizen\n",
      "Role B: Village Secretary\n",
      "Context: Speaker A both questions and provides feedback to change the performance day to Speaker B concerning the residents' art show event. Speaker B has a higher status than Speaker A, but Speaker B still shows respect to Speaker A.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 130:\n",
      "Role A: subordinate\n",
      "Role B: High ranking public officials\n",
      "Context: Speaker A gently suggests to Speaker B to review the reports and data that have been prepared beforehand for study before the discussion activities begin. Speaker A has a lower status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 131:\n",
      "Role A: Citizen\n",
      "Role B: Head of Village\n",
      "Context: Speaker A asks Speaker B why he came to the sub-district office so early in the morning, unlike usual. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 132:\n",
      "Role A: Student\n",
      "Role B: Teacher\n",
      "Context: Speaker A asks Speaker B about the award for being the Best Teacher. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 133:\n",
      "Role A: Junior Public Official\n",
      "Role B: Senior Public official\n",
      "Context: Speaker A congratulates Speaker B and asks about the schedule for training related to his new position. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 134:\n",
      "Role A: Fellow Neighbor (Older)\n",
      "Role B: Fellow Neighbor\n",
      "Context: Speaker A asks Speaker B to lower the volume of the television because his child is sick. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 135:\n",
      "Role A: Moderator or Facilitator\n",
      "Role B: Workshop Participant\n",
      "Context: Speaker A asked Speaker B during the formal event about their role in the workshop activity. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another. \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 136:\n",
      "Role A: Seminar Participant\n",
      "Role B: Guest Speaker\n",
      "Context: Speaker A is a seminar participant who asks Speaker B a question during a formal discussion. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another. \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 137:\n",
      "Role A: Supervisor\n",
      "Role B: Sales trainee\n",
      "Context: Speaker A asks Speaker B about the challenges faced in the field. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 138:\n",
      "Role A: Fellow Neghbour (about the same age)\n",
      "Role B: Fellow Neghbour (about the same age)\n",
      "Context: Speaker A asks Speaker B, who is a neighbor, about the importance of collaboration between organizations while passing each other in the housing complex. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 139:\n",
      "Role A: Moderator\n",
      "Role B: Guest Speaker\n",
      "Context: Speaker A asks Speaker B about a program during a formal public discussion attended by participants from among officials.Speaker A and Speaker B have equal status or position, and they are already accustomed to communicating with each other, , yet both still show mutual highly respect toward one another.    \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 140:\n",
      "Role A: Head of Regional Office\n",
      "Role B: Customer Service Officer\n",
      "Context: Speaker A directly asks Speaker B about the community report results regarding the services provided at the office he leads. Speaker A has a higher status or position than Speaker B.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 141:\n",
      "Role A: construction worker (at the same age)\n",
      "Role B: construction worker (at the same age)\n",
      "Context: Speaker A asks Speaker B during a house renovation activity about how to measure pipes embedded within the wall. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 142:\n",
      "Role A: Mother\n",
      "Role B: Son\n",
      "Context: Speaker A asks and requests Speaker B if he can take his younger sibling to school because she need to finish doing the laundry first. Speaker B has a lower status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 143:\n",
      "Role A: A fellow fisherman\n",
      "Role B: A fellow fisherman\n",
      "Context: Speaker A invites Speaker B to remove the bamboo on the beach that has been making it difficult for them to catch fish. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 144:\n",
      "Role A: Head of Village\n",
      "Role B: Fisherman\n",
      "Context: Speaker A asks Speaker B about the bamboo fence that has been removed from the shoreline without his permission. Speaker B has a lower status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 145:\n",
      "Role A: Victim of theft\n",
      "Role B: a thief\n",
      "Context: Speaker A demands a confession from Speaker B, who was caught red-handed stealing their wallet in a crowd. Speaker B has a lower status or position than Speaker A.  \n",
      "Utterance A: Mboten niyat piye? Wong ketangkep basah ngene kok mboten niyat?! Dompetku endi?!\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 146:\n",
      "Role A: Junior Level Public Official\n",
      "Role B: Director\n",
      "Context: Speaker A asks about Speaker B's willingness to open the training event next week. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 147:\n",
      "Role A: Peer in office\n",
      "Role B: Peer in office\n",
      "Context: Speaker A invites Speaker B to deliver a letter to the Minister. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Iki lho, ana surat penting arep dikirim menyang Pak Menteri. Aku lagi akeh gawean. Kira-kira kowe gelem ngeterke ora?` (This, there's an important letter that needs\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 148:\n",
      "Role A: Childhood friend\n",
      "Role B: Childhood friend\n",
      "Context: Speaker A invites Speaker B to buy a guitar at the store. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Isih ap\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 149:\n",
      "Role A: Junior Level Public Official\n",
      "Role B: Senior Level Public Official\n",
      "Context: Speaker A asks Speaker B for input on the task assigned by the Director. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 150:\n",
      "Role A: Junior Level Public Official\n",
      "Role B: Director\n",
      "Context: Speaker A is asked to come to Speaker B's room to submit the monthly report data. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: *Sugeng enjing, Pak Direktur.* (Good morning, Mr. Director.)\n",
      "Utterance B: *Sugeng enjing. Pripun kabaripun?* (Good morning. How are you?)\n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 151:\n",
      "Role A: Customer\n",
      "Role B: Waiter\n",
      "Context: Speaker A asks Speaker B about the availability of grilled fish at a restaurant. Speaker B has a lower status or position than Speaker A.  \n",
      "Utterance A: Iwak panggang wonten, Mas?` (Are there any grilled fish, Sir/Brother?)\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 152:\n",
      "Role A: a child customer\n",
      "Role B: Seller\n",
      "Context: Speaker A asks Speaker B whether they sell toasted bread. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 153:\n",
      "Role A: Teacher\n",
      "Role B: Student\n",
      "Context: Speaker A asks Speaker B about the multiplication of ten. Speaker B has a lower status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 154:\n",
      "Role A: Fellow Head of School\n",
      "Role B: Fellow Head of School\n",
      "Context: Speaker A invites Speaker B to go together to the meeting at the Department of Education office. Speaker A and Speaker B have equal status but want to show mutual respect to each other.\n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 155:\n",
      "Role A: House owner\n",
      "Role B: housekeeper\n",
      "Context: Speaker A asks Speaker B to clean the dirt on the chair. Speaker B has a lower status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 156:\n",
      "Role A: Friend\n",
      "Role B: Friend\n",
      "Context: Speaker A asks Speaker B to drive the car because he is tired. Speaker A and Speaker B have equal status or position and have familiar interactions.\n",
      "Utterance A: Iyo, semalem nggarap proposal nganti subuh. Mengko lek aku nyupir malah mengantuk, bahaya\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 157:\n",
      "Role A: Son\n",
      "Role B: Mother\n",
      "Context: Speaker A borrows money from Speaker B to pay off a debt. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: *Kula ajeng mbayar utang, Bu. Nanging kirang arta. Punapa Ibu kersa nyilihi arta dhateng kula?* (I need to pay\n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 158:\n",
      "Role A: Policeman\n",
      "Role B: suspected thief\n",
      "Context: Speaker A interrogates Speaker B about a theft in which Speaker B is suspected as the perpetrator. Speaker B has a lower status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 159:\n",
      "Role A: Employee\n",
      "Role B: Employer\n",
      "Context: Speaker A approaches Speaker B to request confirmation regarding the salary he received. Speaker B has a higher status or position than Speaker A.  \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "Instance 160:\n",
      "Role A: Auditor\n",
      "Role B: Auditee\n",
      "Context: Speaker A confirms with Speaker B about the annual report that differs from the tax payment receipts. Speaker A and Speaker B have equal status or position, but they are not yet accustomed to communicating with each other, yet both still show mutual respect toward one another. \n",
      "Utterance A: \n",
      "Utterance B: \n",
      "Model: gemini\n",
      "--------------------------------------------------\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "model1_withHint_A, model1_withHint_B = evaluate_model(model1, tokenizer1, data, True)\n",
    "model2_withHint_A, model2_withHint_B = evaluate_model(model2, tokenizer2, data, True)\n",
    "model3_withHint_A, model3_withHint_B = evaluate_model(model3, tokenizer3, data, True)\n",
    "model4_withHint_A, model4_withHint_B = evaluate_model(model4, tokenizer4, data, True)\n",
    "model5_withHint_A, model5_withHint_B = evaluate_model(model5, tokenizer5, data, True)\n",
    "model6_withHint_A, model6_withHint_B = evaluate_model(model6, tokenizer6, data, True)\n",
    "modelOpenAI_withHint_A, modelOpenAI_withHint_B = evaluate_api_model(data, 'openai', True)\n",
    "modelGemini_withHint_A, modelGemini_withHint_B = evaluate_api_model(data, 'gemini', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00228816",
   "metadata": {},
   "source": [
    "## Load Evaluator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69e83e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./Model/javanese-distilbert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83fc0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7861e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e330b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer):\n",
    "    return tokenizer(examples, truncation=True, padding='max_length', max_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf14929a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a354e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model1_noHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model1_noHint_A\n",
      "Processing model1_noHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model1_noHint_B\n",
      "Processing model1_withHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model1_withHint_A\n",
      "Processing model1_withHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model1_withHint_B\n",
      "Processing model2_noHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model2_noHint_A\n",
      "Processing model2_noHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model2_noHint_B\n",
      "Processing model2_withHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model2_withHint_A\n",
      "Processing model2_withHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model2_withHint_B\n",
      "Processing model3_noHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model3_noHint_A\n",
      "Processing model3_noHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model3_noHint_B\n",
      "Processing model3_withHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model3_withHint_A\n",
      "Processing model3_withHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model3_withHint_B\n",
      "Processing model4_noHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model4_noHint_A\n",
      "Processing model4_noHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model4_noHint_B\n",
      "Processing model4_withHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model4_withHint_A\n",
      "Processing model4_withHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model4_withHint_B\n",
      "Processing model5_noHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model5_noHint_A\n",
      "Processing model5_noHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model5_noHint_B\n",
      "Processing model5_withHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model5_withHint_A\n",
      "Processing model5_withHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model5_withHint_B\n",
      "Processing model6_noHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model6_noHint_A\n",
      "Processing model6_noHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model6_noHint_B\n",
      "Processing model6_withHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model6_withHint_A\n",
      "Processing model6_withHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed model6_withHint_B\n",
      "Processing modelOpenAI_noHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed modelOpenAI_noHint_A\n",
      "Processing modelOpenAI_noHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed modelOpenAI_noHint_B\n",
      "Processing modelOpenAI_withHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed modelOpenAI_withHint_A\n",
      "Processing modelOpenAI_withHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed modelOpenAI_withHint_B\n",
      "Processing modelGemini_noHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed modelGemini_noHint_A\n",
      "Processing modelGemini_noHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed modelGemini_noHint_B\n",
      "Processing modelGemini_withHint_A with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed modelGemini_withHint_A\n",
      "Processing modelGemini_withHint_B with 160 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed modelGemini_withHint_B\n"
     ]
    }
   ],
   "source": [
    "def process_and_predict(data, model_name, hint_status, speaker, tokenizer, trainer):\n",
    "    print(f\"Processing {model_name}_{hint_status}_{speaker} with {len(data)} samples\")\n",
    "\n",
    "    tokenized_data = [preprocess_function(x, tokenizer) for x in data]\n",
    "\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"input_ids\": [item['input_ids'] for item in tokenized_data],\n",
    "        \"attention_mask\": [item['attention_mask'] for item in tokenized_data]\n",
    "    })\n",
    "\n",
    "    output = trainer.predict(dataset)\n",
    "    predictions = output.predictions.argmax(-1)\n",
    "\n",
    "    print(f\"Processed {model_name}_{hint_status}_{speaker}\")\n",
    "    return predictions\n",
    "\n",
    "models = [\"model1\", \"model2\", \"model3\", \"model4\", \"model5\", \"model6\", \"modelOpenAI\", \"modelGemini\"]\n",
    "hint_statuses = [\"noHint\", \"withHint\"]\n",
    "speakers = [\"A\", \"B\"]\n",
    "\n",
    "predictions_dict = {}\n",
    "\n",
    "for model in models:\n",
    "    for hint_status in hint_statuses:\n",
    "        for speaker in speakers:\n",
    "            data_var_name = f\"{model}_{hint_status}_{speaker}\"\n",
    "            predictions = predictions_dict.get(data_var_name, [])\n",
    "\n",
    "            groundtruth_label_key = f\"{speaker.lower()}_utterance_category\"\n",
    "            ground_truth = data1[groundtruth_label_key]\n",
    "            \n",
    "            actual_data = globals()[data_var_name]\n",
    "            \n",
    "            if data:\n",
    "                predictions_dict[data_var_name] = process_and_predict(\n",
    "                    actual_data, model, hint_status, speaker, tokenizer, trainer\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2cdc604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Metrics:\n",
      "hint_status      noHint                                                  \\\n",
      "speaker     A Utterance                            B Utterance            \n",
      "               accuracy f1_score precision  recall    accuracy f1_score   \n",
      "model                                                                     \n",
      "model1           0.4125   0.1514    0.1107  0.2391      0.5875   0.1880   \n",
      "model2           0.4188   0.1502    0.1088  0.2428      0.5750   0.2090   \n",
      "model3           0.4062   0.1630    0.2784  0.2350      0.5500   0.1789   \n",
      "model4           0.4875   0.2725    0.3707  0.3349      0.5812   0.2310   \n",
      "model5           0.4250   0.1821    0.1375  0.2740      0.5750   0.2249   \n",
      "model6           0.4250   0.2249    0.2142  0.2982      0.5812   0.2083   \n",
      "modelGemini      0.4625   0.2279    0.3608  0.2940      0.6000   0.1905   \n",
      "modelOpenAI      0.4312   0.1797    0.3644  0.2490      0.6000   0.1905   \n",
      "\n",
      "hint_status                      withHint                             \\\n",
      "speaker                       A Utterance                              \n",
      "            precision  recall    accuracy f1_score precision  recall   \n",
      "model                                                                  \n",
      "model1         0.1536  0.2423      0.4312   0.1923    0.1618  0.2776   \n",
      "model2         0.2122  0.2512      0.4125   0.1486    0.1078  0.2391   \n",
      "model3         0.1477  0.2268      0.4250   0.1511    0.1090  0.2464   \n",
      "model4         0.2888  0.2621      0.4500   0.2370    0.2837  0.2858   \n",
      "model5         0.2798  0.2573      0.4375   0.1600    0.3606  0.2534   \n",
      "model6         0.1994  0.2538      0.4125   0.1889    0.3976  0.2630   \n",
      "modelGemini    0.1548  0.2474      0.4250   0.1696    0.3662  0.2459   \n",
      "modelOpenAI    0.1548  0.2474      0.4250   0.1635    0.2350  0.2459   \n",
      "\n",
      "hint_status                                         \n",
      "speaker     B Utterance                             \n",
      "               accuracy f1_score precision  recall  \n",
      "model                                               \n",
      "model1           0.5875   0.1873    0.1526  0.2423  \n",
      "model2           0.5750   0.1840    0.1503  0.2371  \n",
      "model3           0.6000   0.2499    0.3004  0.2817  \n",
      "model4           0.5625   0.1837    0.1520  0.2320  \n",
      "model5           0.6062   0.2168    0.2362  0.2641  \n",
      "model6           0.5812   0.1883    0.1550  0.2397  \n",
      "modelGemini      0.6062   0.2155    0.2048  0.2641  \n",
      "modelOpenAI      0.6000   0.1920    0.1569  0.2474  \n",
      "\n",
      "Classification Report by Label:\n",
      "    model hint_status      speaker  label  precision    recall  f1-score  \\\n",
      "0  model1      noHint  A Utterance      0   0.442953  0.956522  0.605505   \n",
      "1  model1      noHint  A Utterance      1   0.000000  0.000000  0.000000   \n",
      "2  model1      noHint  A Utterance      2   0.000000  0.000000  0.000000   \n",
      "3  model1      noHint  A Utterance      3   0.000000  0.000000  0.000000   \n",
      "\n",
      "   support  accuracy  \n",
      "0     69.0   0.93125  \n",
      "1      9.0   0.01875  \n",
      "2      8.0   0.05000  \n",
      "3     74.0   0.00000  \n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics_with_report(y_true, y_pred, model, hint_status, speaker):\n",
    "    overall_metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average='macro'),\n",
    "        \"recall\": recall_score(y_true, y_pred, average='macro'),\n",
    "        \"f1_score\": f1_score(y_true, y_pred, average='macro')\n",
    "    }\n",
    "\n",
    "    report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "    report_rows = []\n",
    "\n",
    "    unique_labels = sorted(set(y_true))\n",
    "    for label in unique_labels:\n",
    "        true_positives = sum((y_pred == label))\n",
    "        total = len(y_true)\n",
    "        \n",
    "        class_accuracy = (true_positives) / total\n",
    "        \n",
    "        metrics = report_dict[str(label)]\n",
    "        row = {\n",
    "            'model': model,\n",
    "            'hint_status': hint_status,\n",
    "            'speaker': speaker,\n",
    "            'label': label,\n",
    "            'precision': metrics['precision'],\n",
    "            'recall': metrics['recall'],\n",
    "            'f1-score': metrics['f1-score'],\n",
    "            'support': metrics['support'],\n",
    "            'accuracy': class_accuracy\n",
    "        }\n",
    "        report_rows.append(row)\n",
    "    \n",
    "    return overall_metrics, report_rows\n",
    "\n",
    "metrics_list = []\n",
    "classification_report_rows = []\n",
    "detailed_results = []\n",
    "\n",
    "for model in models:\n",
    "    for hint_status in hint_statuses:\n",
    "        for speaker in speakers:\n",
    "            data_var_name = f\"{model}_{hint_status}_{speaker}\"\n",
    "            predictions = predictions_dict.get(data_var_name, None)\n",
    "            \n",
    "            if predictions is None or len(predictions) == 0:\n",
    "                continue\n",
    "                \n",
    "            data = globals().get(data_var_name, [])\n",
    "            if not data:\n",
    "                continue\n",
    "            \n",
    "            groundtruth_label_key = f\"{speaker.lower()}_utterance_category\"\n",
    "            ground_truth = dataset[groundtruth_label_key][:len(predictions)]\n",
    "            \n",
    "            if len(ground_truth) != len(predictions):\n",
    "                print(f\"Warning: Mismatch in lengths for {data_var_name}\")\n",
    "                continue\n",
    "\n",
    "            metrics, report_rows = calculate_metrics_with_report(\n",
    "                ground_truth, predictions, model, hint_status, f\"{speaker} Utterance\"\n",
    "            )\n",
    " \n",
    "            metrics[\"model\"] = model\n",
    "            metrics[\"hint_status\"] = hint_status\n",
    "            metrics[\"speaker\"] = f\"{speaker} Utterance\"\n",
    "            metrics_list.append(metrics)\n",
    "            classification_report_rows.extend(report_rows)\n",
    "\n",
    "            for idx, (true_label, pred_label) in enumerate(zip(ground_truth, predictions)):\n",
    "                detailed_results.append({\n",
    "                    \"model\": model,\n",
    "                    \"hint_status\": hint_status,\n",
    "                    \"speaker\": speaker,\n",
    "                    \"instance\": idx,\n",
    "                    \"true_label\": true_label,\n",
    "                    \"predicted_label\": pred_label,\n",
    "                    \"correct\": true_label == pred_label\n",
    "                })\n",
    "\n",
    "results_df = pd.DataFrame(metrics_list)\n",
    "classification_report_df = pd.DataFrame(classification_report_rows)\n",
    "detailed_df = pd.DataFrame(detailed_results)\n",
    "\n",
    "final_df = results_df.pivot_table(\n",
    "    index=\"model\",\n",
    "    columns=[\"hint_status\", \"speaker\"],\n",
    "    values=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    ").round(4)\n",
    "\n",
    "final_df = final_df.reorder_levels([1, 2, 0], axis=1).sort_index(axis=1, level=[0, 1])\n",
    "\n",
    "final_df.to_csv('overall_metrics.csv')\n",
    "classification_report_df.to_csv('classification_report.csv', index=False)\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(final_df)\n",
    "\n",
    "print(\"\\nClassification Report by Label:\")\n",
    "\n",
    "sample_report = classification_report_df[\n",
    "    (classification_report_df['model'] == models[0]) & \n",
    "    (classification_report_df['hint_status'] == hint_statuses[0]) &\n",
    "    (classification_report_df['speaker'] == f\"{speakers[0]} Utterance\")\n",
    "]\n",
    "print(sample_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f1651222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>hint_status</th>\n",
       "      <th colspan=\"8\" halign=\"left\">noHint</th>\n",
       "      <th colspan=\"8\" halign=\"left\">withHint</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker</th>\n",
       "      <th colspan=\"4\" halign=\"left\">A Utterance</th>\n",
       "      <th colspan=\"4\" halign=\"left\">B Utterance</th>\n",
       "      <th colspan=\"4\" halign=\"left\">A Utterance</th>\n",
       "      <th colspan=\"4\" halign=\"left\">B Utterance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>0.2391</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.1536</td>\n",
       "      <td>0.2423</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.2423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>0.4188</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>0.1088</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.2391</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.2371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>0.4062</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.2499</td>\n",
       "      <td>0.3004</td>\n",
       "      <td>0.2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model4</th>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.3707</td>\n",
       "      <td>0.3349</td>\n",
       "      <td>0.5812</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>0.2888</td>\n",
       "      <td>0.2621</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.2858</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model5</th>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.1821</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.3606</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>0.6062</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.2641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model6</th>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.2982</td>\n",
       "      <td>0.5812</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.2630</td>\n",
       "      <td>0.5812</td>\n",
       "      <td>0.1883</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.2397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modelGemini</th>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.3608</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.2474</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.3662</td>\n",
       "      <td>0.2459</td>\n",
       "      <td>0.6062</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.2641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modelOpenAI</th>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.3644</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.2474</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.2459</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.1569</td>\n",
       "      <td>0.2474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hint_status      noHint                                                  \\\n",
       "speaker     A Utterance                            B Utterance            \n",
       "               accuracy f1_score precision  recall    accuracy f1_score   \n",
       "model                                                                     \n",
       "model1           0.4125   0.1514    0.1107  0.2391      0.5875   0.1880   \n",
       "model2           0.4188   0.1502    0.1088  0.2428      0.5750   0.2090   \n",
       "model3           0.4062   0.1630    0.2784  0.2350      0.5500   0.1789   \n",
       "model4           0.4875   0.2725    0.3707  0.3349      0.5812   0.2310   \n",
       "model5           0.4250   0.1821    0.1375  0.2740      0.5750   0.2249   \n",
       "model6           0.4250   0.2249    0.2142  0.2982      0.5812   0.2083   \n",
       "modelGemini      0.4625   0.2279    0.3608  0.2940      0.6000   0.1905   \n",
       "modelOpenAI      0.4312   0.1797    0.3644  0.2490      0.6000   0.1905   \n",
       "\n",
       "hint_status                      withHint                             \\\n",
       "speaker                       A Utterance                              \n",
       "            precision  recall    accuracy f1_score precision  recall   \n",
       "model                                                                  \n",
       "model1         0.1536  0.2423      0.4312   0.1923    0.1618  0.2776   \n",
       "model2         0.2122  0.2512      0.4125   0.1486    0.1078  0.2391   \n",
       "model3         0.1477  0.2268      0.4250   0.1511    0.1090  0.2464   \n",
       "model4         0.2888  0.2621      0.4500   0.2370    0.2837  0.2858   \n",
       "model5         0.2798  0.2573      0.4375   0.1600    0.3606  0.2534   \n",
       "model6         0.1994  0.2538      0.4125   0.1889    0.3976  0.2630   \n",
       "modelGemini    0.1548  0.2474      0.4250   0.1696    0.3662  0.2459   \n",
       "modelOpenAI    0.1548  0.2474      0.4250   0.1635    0.2350  0.2459   \n",
       "\n",
       "hint_status                                         \n",
       "speaker     B Utterance                             \n",
       "               accuracy f1_score precision  recall  \n",
       "model                                               \n",
       "model1           0.5875   0.1873    0.1526  0.2423  \n",
       "model2           0.5750   0.1840    0.1503  0.2371  \n",
       "model3           0.6000   0.2499    0.3004  0.2817  \n",
       "model4           0.5625   0.1837    0.1520  0.2320  \n",
       "model5           0.6062   0.2168    0.2362  0.2641  \n",
       "model6           0.5812   0.1883    0.1550  0.2397  \n",
       "modelGemini      0.6062   0.2155    0.2048  0.2641  \n",
       "modelOpenAI      0.6000   0.1920    0.1569  0.2474  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d0bc814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hint_status</th>\n",
       "      <th>speaker</th>\n",
       "      <th>instance</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model1</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model1</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model1</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model1</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model1</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            model hint_status speaker  instance  true_label  predicted_label  \\\n",
       "0          model1      noHint       A         0           0                0   \n",
       "1          model1      noHint       A         1           1                0   \n",
       "2          model1      noHint       A         2           0                0   \n",
       "3          model1      noHint       A         3           0                0   \n",
       "4          model1      noHint       A         4           0                0   \n",
       "...           ...         ...     ...       ...         ...              ...   \n",
       "5115  modelGemini    withHint       B       155           0                0   \n",
       "5116  modelGemini    withHint       B       156           0                0   \n",
       "5117  modelGemini    withHint       B       157           3                2   \n",
       "5118  modelGemini    withHint       B       158           0                0   \n",
       "5119  modelGemini    withHint       B       159           2                0   \n",
       "\n",
       "      correct  \n",
       "0        True  \n",
       "1       False  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  \n",
       "...       ...  \n",
       "5115     True  \n",
       "5116     True  \n",
       "5117    False  \n",
       "5118     True  \n",
       "5119    False  \n",
       "\n",
       "[5120 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70819419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hint_status</th>\n",
       "      <th>speaker</th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A Utterance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A Utterance</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.01250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A Utterance</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.15625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A Utterance</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.05000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>noHint</td>\n",
       "      <td>B Utterance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>noHint</td>\n",
       "      <td>B Utterance</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>noHint</td>\n",
       "      <td>B Utterance</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>noHint</td>\n",
       "      <td>B Utterance</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>A Utterance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.625592</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.88750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>A Utterance</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>A Utterance</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>A Utterance</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.01250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B Utterance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B Utterance</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B Utterance</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>modelGemini</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B Utterance</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model hint_status      speaker  label  precision    recall  \\\n",
       "112  modelGemini      noHint  A Utterance      0   0.528000  0.956522   \n",
       "113  modelGemini      noHint  A Utterance      1   0.000000  0.000000   \n",
       "114  modelGemini      noHint  A Utterance      2   0.040000  0.125000   \n",
       "115  modelGemini      noHint  A Utterance      3   0.875000  0.094595   \n",
       "116  modelGemini      noHint  B Utterance      0   0.619355  0.989691   \n",
       "117  modelGemini      noHint  B Utterance      1   0.000000  0.000000   \n",
       "118  modelGemini      noHint  B Utterance      2   0.000000  0.000000   \n",
       "119  modelGemini      noHint  B Utterance      3   0.000000  0.000000   \n",
       "120  modelGemini    withHint  A Utterance      0   0.464789  0.956522   \n",
       "121  modelGemini    withHint  A Utterance      1   0.000000  0.000000   \n",
       "122  modelGemini    withHint  A Utterance      2   0.000000  0.000000   \n",
       "123  modelGemini    withHint  A Utterance      3   1.000000  0.027027   \n",
       "124  modelGemini    withHint  B Utterance      0   0.619355  0.989691   \n",
       "125  modelGemini    withHint  B Utterance      1   0.000000  0.000000   \n",
       "126  modelGemini    withHint  B Utterance      2   0.200000  0.066667   \n",
       "127  modelGemini    withHint  B Utterance      3   0.000000  0.000000   \n",
       "\n",
       "     f1-score  support  accuracy  \n",
       "112  0.680412     69.0   0.78125  \n",
       "113  0.000000      9.0   0.01250  \n",
       "114  0.060606      8.0   0.15625  \n",
       "115  0.170732     74.0   0.05000  \n",
       "116  0.761905     97.0   0.96875  \n",
       "117  0.000000     11.0   0.00000  \n",
       "118  0.000000     15.0   0.03125  \n",
       "119  0.000000     37.0   0.00000  \n",
       "120  0.625592     69.0   0.88750  \n",
       "121  0.000000      9.0   0.00000  \n",
       "122  0.000000      8.0   0.10000  \n",
       "123  0.052632     74.0   0.01250  \n",
       "124  0.761905     97.0   0.96875  \n",
       "125  0.000000     11.0   0.00000  \n",
       "126  0.100000     15.0   0.03125  \n",
       "127  0.000000     37.0   0.00000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report_df[classification_report_df[\"model\"]==\"modelGemini\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e7400eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>hint_status</th>\n",
       "      <th>speaker</th>\n",
       "      <th>instance</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>model2</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>model2</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>model2</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>model2</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>model2</td>\n",
       "      <td>noHint</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>model2</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>model2</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>model2</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>model2</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>model2</td>\n",
       "      <td>withHint</td>\n",
       "      <td>B</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model hint_status speaker  instance  true_label  predicted_label  \\\n",
       "640   model2      noHint       A         0           0                0   \n",
       "641   model2      noHint       A         1           1                0   \n",
       "642   model2      noHint       A         2           0                0   \n",
       "643   model2      noHint       A         3           0                0   \n",
       "644   model2      noHint       A         4           0                0   \n",
       "...      ...         ...     ...       ...         ...              ...   \n",
       "1275  model2    withHint       B       155           0                0   \n",
       "1276  model2    withHint       B       156           0                0   \n",
       "1277  model2    withHint       B       157           3                0   \n",
       "1278  model2    withHint       B       158           0                0   \n",
       "1279  model2    withHint       B       159           2                0   \n",
       "\n",
       "      correct  \n",
       "640      True  \n",
       "641     False  \n",
       "642      True  \n",
       "643      True  \n",
       "644      True  \n",
       "...       ...  \n",
       "1275     True  \n",
       "1276     True  \n",
       "1277    False  \n",
       "1278     True  \n",
       "1279    False  \n",
       "\n",
       "[640 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_df[detailed_df['model'] == 'model2']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
