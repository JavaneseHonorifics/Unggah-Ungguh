{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa51cee",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Task 3: Crosslingual Honorific Translation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de97983",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94bde86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-proto 1.26.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch evaluate transformers accelerate>=0.26.0 sentencepiece einops sacrebleu google.generativeai openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5468cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import google.generativeai as genai\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from dataclasses import dataclass\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer, \n",
    "    GenerationConfig, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from huggingface_hub import login\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72129821",
   "metadata": {},
   "source": [
    "## Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4dccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "OPEN_API_KEY = os.getenv(\"OPEN_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "MODELS = [\n",
    "    \"GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct\",\n",
    "    \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"sail/Sailor2-8B\",\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    \"google/gemma-2-9b-it\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8516c5",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebfe9a38-f481-4459-8823-fa705e932c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c595463752854d759081f02aa32e6bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3fbd490c0e4160bf3bfe845251a105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.csv:   0%|          | 0.00/807k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beba6c6ac7bc40beb1c97982971a0038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"JavaneseHonorifics/Unggah-Ungguh\", \"translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24613c44-33a2-45ca-975a-01056e26795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['index', 'label', 'javanese sentence', 'group', 'indonesian sentence', 'english sentence'],\n",
       "        num_rows: 4024\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f09f49-c6be-4a36-a8cb-435d10066d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 2,\n",
       " 'label': 2,\n",
       " 'javanese sentence': 'Sampeyan mbekta jeram menika!',\n",
       " 'group': 1,\n",
       " 'indonesian sentence': 'Membawalah jeruk itu.',\n",
       " 'english sentence': 'Bring that orange.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe7b4d-910f-4e9f-aa86-d7a9a8776261",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaca15f",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e627345",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "797d1f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267843c9de5f46cdb0a642ffccce874e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/scratch/2497254.1.ivcbuyin/ipykernel_1556897/4122142561.py\", line 5, in <module>\n",
      "    model1 = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 4256, in from_pretrained\n",
      "    model.generation_config = GenerationConfig.from_pretrained(\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 1102, in from_pretrained\n",
      "    config = cls.from_dict(config_dict, **kwargs)\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 1137, in from_dict\n",
      "    config = cls(**{**config_dict, **kwargs})\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 509, in __init__\n",
      "    self.validate(is_init=True)\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py\", line 789, in validate\n",
      "    logger.warning_once(\n",
      "  File \"/usr2/collab/mrfarhan/.local/lib/python3.10/site-packages/transformers/utils/logging.py\", line 328, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.'\n",
      "Arguments: (<class 'UserWarning'>,)\n"
     ]
    }
   ],
   "source": [
    "model_name_1 = MODELS[0] # \"GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct\"\n",
    "\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model_name_1)\n",
    "\n",
    "model1 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_1,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb16c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92f359a6b304eeaa14a32ebeac101a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_2 = MODELS[1] # \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\"\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_name_2)\n",
    "\n",
    "model2 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_2,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2b34259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296a11f46a5449b3bbdfad2198d90203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_3 = MODELS[2] # \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(model_name_3)\n",
    "\n",
    "model3 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_3,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73d10611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50192c789bbf42d4b244c1795988ee4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_4 = MODELS[3] # \"sail/Sailor2-8B\"\n",
    "\n",
    "tokenizer4 = AutoTokenizer.from_pretrained(model_name_4)\n",
    "\n",
    "model4 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_4,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75701755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7629cd954a43f3b6b2d5a749893707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_5 = MODELS[4] # \"google/gemma-2-2b-it\"\n",
    "\n",
    "tokenizer5 = AutoTokenizer.from_pretrained(model_name_5)\n",
    "\n",
    "model5 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_5,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9bbdfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9327d10b794b63b2f9efa090a070fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_6 = MODELS[5] # \"google/gemma-2-9b-it\"\n",
    "\n",
    "tokenizer6 = AutoTokenizer.from_pretrained(model_name_6)\n",
    "\n",
    "model6 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_6,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=f\"./cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca82e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelOpenAI = OpenAI(api_key=OPEN_API_KEY)\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "ModelGemini = genai.GenerativeModel('gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbc7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, min_delay_ms=1000):\n",
    "        self.min_delay_ms = min_delay_ms\n",
    "        self.last_call = datetime.now()\n",
    "    \n",
    "    def wait(self):\n",
    "        now = datetime.now()\n",
    "        elapsed_ms = (now - self.last_call).total_seconds() * 1000\n",
    "        \n",
    "        if elapsed_ms < self.min_delay_ms:\n",
    "            remaining_ms = self.min_delay_ms - elapsed_ms\n",
    "            while (datetime.now() - now).total_seconds() * 1000 < remaining_ms:\n",
    "                pass\n",
    "        \n",
    "        self.last_call = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b11036f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "\n",
    "@dataclass\n",
    "class TranslationResult:\n",
    "    predicted: List[str]\n",
    "    target: List[str]\n",
    "    bleu_score: float\n",
    "    chrf_score: float\n",
    "    groups: List[int]\n",
    "\n",
    "class JavaneseTranslationEvaluator:\n",
    "    def __init__(self, model, tokenizer=None):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bleu = BLEU()\n",
    "        self.chrf = CHRF(word_order=2)  # Using chrF++ (word_order=2)\n",
    "        \n",
    "    def _create_indo_to_javanese_prompt(self, indo_text: str, target_level: int) -> str:\n",
    "        honorific_levels = {\n",
    "            0: \"Ngoko (informal, familiar conversations)\",\n",
    "            1: \"Ngoko Alus (respectful but informal)\",\n",
    "            2: \"Krama (polite but not overly formal)\",\n",
    "            3: \"Krama Alus (highly respectful)\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"Translate this Indonesian sentence to Javanese using {honorific_levels[target_level]}:\n",
    "Indonesian: {indo_text}\n",
    "Javanese: \"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def _create_javanese_to_indo_prompt(self, javanese_text: str) -> str:\n",
    "        prompt = f\"\"\"Translate this Javanese sentence to Indonesian:\n",
    "Javanese: {javanese_text}\n",
    "Indonesian: \"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def generate_translation(self, prompt: str) -> str:\n",
    "        torch.cuda.empty_cache()\n",
    "        rate_limiter = RateLimiter(min_delay_ms=1000)\n",
    "        try:\n",
    "            if self.model == ModelOpenAI:\n",
    "                response = ModelOpenAI.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=100,\n",
    "                    top_p=0.9\n",
    "                )\n",
    "                translation = response.choices[0].message.content\n",
    "                torch.cuda.empty_cache()\n",
    "                rate_limiter.wait()\n",
    "            elif self.model == ModelGemini:\n",
    "                response = ModelGemini.generate_content(\n",
    "                    prompt,\n",
    "                    generation_config=genai.types.GenerationConfig(\n",
    "                        temperature=0.7,\n",
    "                        top_p=0.9,\n",
    "                        top_k=50,\n",
    "                        max_output_tokens=100\n",
    "                    )\n",
    "                )\n",
    "                translation = response.text\n",
    "                torch.cuda.empty_cache()\n",
    "                rate_limiter.wait()\n",
    "            else:\n",
    "                generation_config = {\n",
    "                    'num_return_sequences': 1,\n",
    "                    'temperature': 0.7,\n",
    "                    'top_p': 0.9,\n",
    "                    'top_k': 50,\n",
    "                    'pad_token_id': self.tokenizer.pad_token_id,\n",
    "                    'do_sample': True,\n",
    "                    'early_stopping': True,\n",
    "                    'repetition_penalty': 1.2,\n",
    "                    'min_length': 10,\n",
    "                    'max_new_tokens': 100\n",
    "                }\n",
    "                input_ids = self.tokenizer(prompt, return_tensors='pt').input_ids\n",
    "                outputs = self.model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    **generation_config\n",
    "                )\n",
    "                translation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                torch.cuda.empty_cache()\n",
    "            translation = translation.split(\":\")[-1].strip()\n",
    "            torch.cuda.empty_cache()\n",
    "            return translation if translation else \"EMPTY_TRANSLATION\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in generation: {str(e)}\")\n",
    "            return \"EMPTY_TRANSLATION\"\n",
    "            \n",
    "    def _calculate_scores(self, predictions: List[str], targets: List[str]) -> Tuple[float, float]:\n",
    "        \"\"\"Calculate BLEU and chrF++ scores with error handling.\"\"\"\n",
    "        try:\n",
    "            valid_pairs = [(p, t) for p, t in zip(predictions, targets) \n",
    "                          if p != \"EMPTY_TRANSLATION\" and p and t]\n",
    "            \n",
    "            if not valid_pairs:\n",
    "                return 0.0, 0.0\n",
    "                \n",
    "            valid_preds, valid_targets = zip(*valid_pairs)\n",
    "            \n",
    "            bleu_score = self.bleu.corpus_score(\n",
    "                valid_preds, \n",
    "                [valid_targets]\n",
    "            ).score\n",
    "            \n",
    "            chrf_score = self.chrf.corpus_score(\n",
    "                valid_preds,\n",
    "                [valid_targets]\n",
    "            ).score\n",
    "            \n",
    "            return bleu_score, chrf_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating scores: {str(e)}\")\n",
    "            return 0.0, 0.0\n",
    "            \n",
    "    def evaluate_translations(self, dataset: List[Dict]) -> Dict[str, TranslationResult]:\n",
    "        results = {\n",
    "            'indo_to_java_0': [], 'indo_to_java_1': [], \n",
    "            'indo_to_java_2': [], 'indo_to_java_3': [],\n",
    "            'java_0_to_indo': [], 'java_1_to_indo': [],\n",
    "            'java_2_to_indo': [], 'java_3_to_indo': []\n",
    "        }\n",
    "        targets = {k: [] for k in results.keys()}\n",
    "        groups = {k: [] for k in results.keys()}\n",
    "\n",
    "        honorific_levels = {\n",
    "            0: \"Ngoko\",\n",
    "            1: \"Ngoko Alus\",\n",
    "            2: \"Krama\",\n",
    "            3: \"Krama Alus\"\n",
    "        }\n",
    "\n",
    "        grouped_data = {}\n",
    "        for item in dataset:\n",
    "            if 'group' not in item or 'indo' not in item or 'sentence' not in item or item['sentence'] is None:\n",
    "                print(f\"Skipping invalid data item: {item}\")\n",
    "                continue\n",
    "\n",
    "            group = item['group']\n",
    "            if group not in grouped_data:\n",
    "                grouped_data[group] = {'indo': item['indo'], 'translations': {}}\n",
    "\n",
    "            if item['sentence'] is not None and item['sentence'].strip():\n",
    "                grouped_data[group]['translations'][item['label']] = item['sentence']\n",
    "\n",
    "        for group, data in grouped_data.items():\n",
    "            if 'indo' not in data or not data['indo']:\n",
    "                print(f\"Skipping group {group}: No Indonesian text found\")\n",
    "                continue\n",
    "\n",
    "            indo_text = data['indo']\n",
    "\n",
    "            for level in range(4):\n",
    "                if level in data['translations'] and data['translations'][level]:\n",
    "                    prompt = self._create_indo_to_javanese_prompt(indo_text, level)\n",
    "                    prediction = self.generate_translation(prompt)\n",
    "\n",
    "                    key = f'indo_to_java_{level}'\n",
    "                    results[key].append(prediction)\n",
    "                    targets[key].append(data['translations'][level])\n",
    "                    groups[key].append(group)\n",
    "\n",
    "                    if level == 0:\n",
    "                        print(f\"\\nTranslation from Indonesian to {honorific_levels[level]}:\")\n",
    "                        print(f\"Indonesian: {indo_text}\")\n",
    "                        print(f\"Generation: {prediction}\")\n",
    "                        print(f\"Gold: {data['translations'][level]}\")\n",
    "                        print(\"-\" * 50)\n",
    "\n",
    "            for level in range(4):\n",
    "                if level in data['translations'] and data['translations'][level]:\n",
    "                    javanese_text = data['translations'][level]\n",
    "                    prompt = self._create_javanese_to_indo_prompt(javanese_text)\n",
    "                    prediction = self.generate_translation(prompt)\n",
    "\n",
    "                    key = f'java_{level}_to_indo'\n",
    "                    results[key].append(prediction)\n",
    "                    targets[key].append(indo_text)\n",
    "                    groups[key].append(group)\n",
    "\n",
    "                    if level == 0:\n",
    "                        print(f\"\\nTranslation from {honorific_levels[level]} to Indonesian:\")\n",
    "                        print(f\"Javanese: {javanese_text}\")\n",
    "                        print(f\"Generation: {prediction}\")\n",
    "                        print(f\"Gold: {indo_text}\")\n",
    "                        print(\"-\" * 50)\n",
    "\n",
    "        final_results = {}\n",
    "        for key in results:\n",
    "            if results[key] and all(t is not None for t in targets[key]):\n",
    "                bleu_score, chrf_score = self._calculate_scores(results[key], targets[key])\n",
    "\n",
    "                final_results[key] = TranslationResult(\n",
    "                    predicted=results[key],\n",
    "                    target=targets[key],\n",
    "                    bleu_score=bleu_score,\n",
    "                    chrf_score=chrf_score,\n",
    "                    groups=groups[key]\n",
    "                )\n",
    "\n",
    "        return final_results\n",
    "\n",
    "def print_evaluation_results(results: Dict[str, TranslationResult]):\n",
    "    translation_types = {\n",
    "        'indo_to_java': 'Indonesian to Javanese',\n",
    "        'java_to_indo': 'Javanese to Indonesian'\n",
    "    }\n",
    "    \n",
    "    honorific_levels = {\n",
    "        '0': 'Ngoko',\n",
    "        '1': 'Ngoko Alus',\n",
    "        '2': 'Krama',\n",
    "        '3': 'Krama Alus'\n",
    "    }\n",
    "    \n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for key, result in results.items():\n",
    "        direction = 'indo_to_java' if 'indo_to_java' in key else 'java_to_indo'\n",
    "        level = key.split('_')[-1] if 'indo_to_java' in key else key.split('_')[1]\n",
    "        \n",
    "        print(f\"\\n{translation_types[direction]} ({honorific_levels[level]}):\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"BLEU Score: {result.bleu_score:.2f}\")\n",
    "        print(f\"chrF++ Score: {result.chrf_score:.2f}\")\n",
    "\n",
    "def calculate_average_scores(results: Dict[str, TranslationResult]) -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"Calculate average BLEU and chrF++ scores for each direction and overall.\"\"\"\n",
    "    \n",
    "    scores = {\n",
    "        'indo_to_java': {'bleu': [], 'chrf': []},\n",
    "        'java_to_indo': {'bleu': [], 'chrf': []},\n",
    "        'overall': {'bleu': [], 'chrf': []}\n",
    "    }\n",
    "    \n",
    "    for key, result in results.items():\n",
    "        direction = 'indo_to_java' if 'indo_to_java' in key else 'java_to_indo'\n",
    "\n",
    "        if result.bleu_score > 0 or result.chrf_score > 0:\n",
    "            scores[direction]['bleu'].append(result.bleu_score)\n",
    "            scores[direction]['chrf'].append(result.chrf_score)\n",
    "            scores['overall']['bleu'].append(result.bleu_score)\n",
    "            scores['overall']['chrf'].append(result.chrf_score)\n",
    "\n",
    "    averages = {}\n",
    "    for direction in scores:\n",
    "        averages[direction] = {\n",
    "            'bleu': np.mean(scores[direction]['bleu']) if scores[direction]['bleu'] else 0.0,\n",
    "            'chrf': np.mean(scores[direction]['chrf']) if scores[direction]['chrf'] else 0.0\n",
    "        }\n",
    "    \n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f2d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Model6...\n",
      "\n",
      "Evaluation Results:\n",
      "================================================================================\n",
      "    Model indo_to_java_0        indo_to_java_1        indo_to_java_2         \\\n",
      "                    BLEU chrF++           BLEU chrF++           BLEU chrF++   \n",
      "0  Model6           0.43  11.85           0.29  11.45           0.12  10.98   \n",
      "\n",
      "  indo_to_java_3        java_0_to_indo        java_1_to_indo         \\\n",
      "            BLEU chrF++           BLEU chrF++           BLEU chrF++   \n",
      "0           0.11  11.03           3.29  20.43           2.22   17.7   \n",
      "\n",
      "  java_2_to_indo        java_3_to_indo         \n",
      "            BLEU chrF++           BLEU chrF++  \n",
      "0           1.55  15.88           1.77  15.27  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "\n",
    "def evaluate_all_models(models_dict: Dict, data: List[Dict]) -> pd.DataFrame:\n",
    "    results_list = []\n",
    "\n",
    "    directions = [\n",
    "        'indo_to_java_0', 'indo_to_java_1', 'indo_to_java_2', 'indo_to_java_3',\n",
    "        'java_0_to_indo', 'java_1_to_indo', 'java_2_to_indo', 'java_3_to_indo'\n",
    "    ]\n",
    "    \n",
    "    for model_name, (model, tokenizer) in models_dict.items():\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        evaluator = JavaneseTranslationEvaluator(model, tokenizer)\n",
    "        results = evaluator.evaluate_translations(data)\n",
    "\n",
    "        row_data = {'Model': model_name}\n",
    "\n",
    "        for direction in directions:\n",
    "            if direction in results:\n",
    "                row_data[f'{direction}_BLEU'] = results[direction].bleu_score\n",
    "                row_data[f'{direction}_chrF++'] = results[direction].chrf_score\n",
    "            else:\n",
    "                row_data[f'{direction}_BLEU'] = 0.0\n",
    "                row_data[f'{direction}_chrF++'] = 0.0\n",
    "        \n",
    "        results_list.append(row_data)\n",
    "\n",
    "    df = pd.DataFrame(results_list)\n",
    "\n",
    "    first_level = []\n",
    "    second_level = []\n",
    "    \n",
    "    for direction in directions:\n",
    "        first_level.extend([direction, direction])\n",
    "        second_level.extend(['BLEU', 'chrF++'])\n",
    "\n",
    "    columns = pd.MultiIndex.from_arrays([\n",
    "        ['Model'] + first_level,\n",
    "        [''] + second_level\n",
    "    ])\n",
    "\n",
    "    df_columns = ['Model']\n",
    "    for direction in directions:\n",
    "        df_columns.extend([f'{direction}_BLEU', f'{direction}_chrF++'])\n",
    "    \n",
    "    df = df[df_columns]\n",
    "\n",
    "    df.columns = columns\n",
    "\n",
    "    numeric_columns = df.columns[1:]\n",
    "    df[numeric_columns] = df[numeric_columns].round(2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "models_dict = {\n",
    "    'Model1': (model1, tokenizer1),\n",
    "    'Model2': (model2, tokenizer2),\n",
    "    'Model3': (model3, tokenizer3),\n",
    "    'Model4': (model4, tokenizer4),\n",
    "    'Model5': (model5, tokenizer5),\n",
    "    'Model6': (model6, tokenizer6),\n",
    "    'OpenAI': (ModelOpenAI, None),\n",
    "    'Gemini': (ModelGemini, None)\n",
    "}\n",
    "\n",
    "results_df = evaluate_all_models(models_dict, dataset)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('../../results/task3/translation_evaluation_results_<YOUR MODEL>.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c6525db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">indo_to_java_0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">indo_to_java_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">indo_to_java_2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">indo_to_java_3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">java_0_to_indo</th>\n",
       "      <th colspan=\"2\" halign=\"left\">java_1_to_indo</th>\n",
       "      <th colspan=\"2\" halign=\"left\">java_2_to_indo</th>\n",
       "      <th colspan=\"2\" halign=\"left\">java_3_to_indo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF++</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF++</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF++</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF++</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF++</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF++</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF++</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF++</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model6</td>\n",
       "      <td>0.43</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.29</td>\n",
       "      <td>11.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10.98</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.03</td>\n",
       "      <td>3.29</td>\n",
       "      <td>20.43</td>\n",
       "      <td>2.22</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.55</td>\n",
       "      <td>15.88</td>\n",
       "      <td>1.77</td>\n",
       "      <td>15.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model indo_to_java_0        indo_to_java_1        indo_to_java_2         \\\n",
       "                    BLEU chrF++           BLEU chrF++           BLEU chrF++   \n",
       "0  Model6           0.43  11.85           0.29  11.45           0.12  10.98   \n",
       "\n",
       "  indo_to_java_3        java_0_to_indo        java_1_to_indo         \\\n",
       "            BLEU chrF++           BLEU chrF++           BLEU chrF++   \n",
       "0           0.11  11.03           3.29  20.43           2.22   17.7   \n",
       "\n",
       "  java_2_to_indo        java_3_to_indo         \n",
       "            BLEU chrF++           BLEU chrF++  \n",
       "0           1.55  15.88           1.77  15.27  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
